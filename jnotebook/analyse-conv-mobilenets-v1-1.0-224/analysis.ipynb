{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# [Collective Knowledge](http://cknowledge.org): Community-driven benchmarking and optimization of computing systems - from classical to quantum\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Artificial Intelligence and Machine Learning](http://cknowledge.org/ai)\n",
    "  - [ACM Reproducible Quality-Efficient Systems Tournaments](http://cknowledge.org/request) ([ReQuEST initiative](http://cknowledge.org/request.html#organizers))\n",
    "  - [AI artifacts](http://cknowledge.org/ai-artifacts) ([cTuning foundation](http://ctuning.org))\n",
    "  - [Android app](https://play.google.com/store/apps/details?id=openscience.crowdsource.video.experiments) (dividiti)\n",
    "  - [Desktop app](https://github.com/dividiti/ck-crowdsource-dnn-optimization) (dividiti)\n",
    "  - [CK-Caffe](https://github.com/dividiti/ck-caffe) (Berkeley)\n",
    "  - [CK-Caffe2](https://github.com/ctuning/ck-caffe2) (Facebook)\n",
    "  - [CK-CNTK](https://github.com/ctuning/ck-cntk) (Microsoft)\n",
    "  - [CK-KaNN](https://github.com/ctuning/ck-kann) (Kalray)\n",
    "  - [CK-MVNC](https://github.com/ctuning/ck-mvnc) (Movidius / Intel)\n",
    "  - [CK-MXNet](https://github.com/ctuning/ck-mxnet) (Apache)\n",
    "  - [CK-NNTest](https://github.com/ctuning/ck-nntest) (cTuning foundation)\n",
    "  - [CK-PyTorch](https://github.com/ctuning/ck-pytorch) (Facebook)\n",
    "  - [CK-TensorFlow](https://github.com/ctuning/ck-tensorflow) (Google)\n",
    "  - [CK-TensorRT](https://github.com/ctuning/ck-tensorrt) (NVIDIA)\n",
    "  - [CK-TVM](https://github.com/ctuning/ck-tvm) ([University of Washington](https://tvm.ai/about))\n",
    "  - etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# CK-NNTest: Collaboratively validating, benchmarking and optimizing neural net operators across platforms, frameworks and datasets\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Overview](#overview)\n",
    "1. [Platforms](#platforms)\n",
    "  1. [Firefly RK3399](#platforms_firefly)\n",
    "1. [Experimental data](#data) [for developers]\n",
    "1. [Data wrangling code](#code) [for developers]\n",
    "1. [MobileNets-v1-1.0-224 (\"baseline\")](#analysis_mobilenets_baseline)\n",
    "  1. [Experimental setup](#analysis_mobilenets_baseline_setup)\n",
    "  1. [All experiments](#analysis_mobilenets_baseline_experiments_all)\n",
    "  1. [Failed experiments](#analysis_mobilenets_baseline_experiments_failed)\n",
    "  1. [Plot by platform (microseconds)](#analysis_mobilenets_baseline_plot_platform_us)\n",
    "  1. [Plot by platform (GFLOPS)](#analysis_mobilenets_baseline_plot_platform_gflops)\n",
    "  1. [Plot speedup](#analysis_mobilenets_baseline_plot_speedup)\n",
    "1. [MobileNets-v1-1.0-224 (\"baseline\"): profiler](#analysis_mobilenets_baseline_profiler) **TODO**\n",
    "1. [MobileNets-v1-0.75-160 (\"reduced\")](#analysis_mobilenets_reduced) **TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook studies performance (execution time) of NN operators on the following platforms:\n",
    "- [Firefly RK3399](http://en.t-firefly.com/en/firenow/Firefly_RK3399) (`firefly`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platforms\"></a>\n",
    "## Platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platforms_firefly\"></a>\n",
    "### T-Firefly RK3399"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Chip:\n",
    "    - [Rockchip RK3399](http://rockchip.wikidot.com/rk3399)\n",
    "  - CPU (\"big\"):\n",
    "    - ARM&reg; Cortex&reg;-A72 architecture\n",
    "    - Max clock 1800 MHz;\n",
    "    - 2 cores;\n",
    "  - CPU (\"LITTLE\"):\n",
    "    - ARM&reg; Cortex&reg;-A53 architecture;\n",
    "    - Max clock 1416 MHz;\n",
    "    - 4 cores;\n",
    "  - GPU:\n",
    "    - ARM&reg; Mali&trade;-T860 architecture;\n",
    "    - Max clock 800 MHz;\n",
    "    - 4 cores;\n",
    "    - OpenCL driver:\n",
    "```\n",
    "$ ck run program:tool-print-opencl-devices | grep \"OpenCL C version:\"\n",
    "OpenCL C version: OpenCL C 1.2 v1.r13p0-00rel0-git(a4271c9).31ba04af2d3c01618138bef3aed66c2c\n",
    "```\n",
    "\n",
    "  - RAM:\n",
    "    - Samsung dual-channel DDR3;\n",
    "    - 4 GB;\n",
    "  - BSP:    \n",
    "    - [Firefly-rk3399_xubuntu1604_201711301130.7z](https://drive.google.com/drive/u/0/folders/1lbaR7XVyHT4SnXkJ2ybj5YXAzAjDBWfT)\n",
    "    \n",
    "```\n",
    "$ cat /etc/lsb-release \n",
    "DISTRIB_ID=Ubuntu\n",
    "DISTRIB_RELEASE=16.04\n",
    "DISTRIB_CODENAME=xenial\n",
    "DISTRIB_DESCRIPTION=\"Ubuntu 16.04.5 LTS\"\n",
    "$ uname -a\n",
    "Linux firefly 4.4.77 #554 SMP Thu Nov 30 11:30:11 HKT 2017 aarch64 aarch64 aarch64 GNU/Linux\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firefly_model = 'Rockchip RK3399 Firefly Board (Linux Opensource)\\x00'\n",
    "firefly_name  = 'Firefly RK3399'\n",
    "firefly_id    = 'firefly'\n",
    "firefly_gpu   = 'Mali-T860 MP4'\n",
    "firefly_gpu_mhz = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_id = {\n",
    "    firefly_model : firefly_id,\n",
    "}\n",
    "id_to_name = {\n",
    "    firefly_id : firefly_name,\n",
    "}\n",
    "id_to_gpu = {\n",
    "    firefly_id : firefly_gpu,\n",
    "}\n",
    "id_to_gpu_mhz = {\n",
    "    firefly_id : firefly_gpu_mhz,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## Get the experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiments use packages, programs and scripts from the public [CK-NNTest](https://github.com/ctuning/ck-nntest) repository:\n",
    "```\n",
    "$ ck pull repo:ck-nntest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Arm Compute Library variants of interest (`v18.05`) were installed on the experimental platforms as follows:\n",
    "```\n",
    "$ ck install ck-math:package:lib-armcl-opencl-18.05 \\\n",
    "--env.USE_GRAPH=ON --env.USE_NEON=ON --env.USE_EMBEDDED_KERNELS=ON\n",
    "```\n",
    "\n",
    "The experimental data was collected and archived on each platform as follows:\n",
    "```\n",
    "$ ck zip local:experiment:nntest*mobilenets-v1-1.0-224-<platform>* \\\n",
    "  --archive_name=ck-nntest-mobilenets-v1-1.0-224-<platform>.zip\n",
    "```\n",
    "(and then merged on a desktop machine into a single repository).\n",
    "\n",
    "The data can be downloaded and registered with CK as follows:\n",
    "```\n",
    "$ wget https://www.dropbox.com/s/9lbp38v52y6mv85/ck-nntest-mobilenets-v1-1.0-224-firefly.zip\n",
    "$ ck add repo --zip=ck-nntest-mobilenets-v1-1.0-224-firefly.zip --quiet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_uoa = 'ck-nntest-mobilenets-v1-1.0-224-firefly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"code\"></a>\n",
    "## Data wrangling code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** Please ignore this section if you are not interested in re-running or modifying this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scientific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some of the scientific packages are missing, please install them using:\n",
    "```\n",
    "# pip install jupyter pandas numpy matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colormap = cm.autumn\n",
    "default_figwidth = 24\n",
    "default_figdpi = 200\n",
    "default_fontsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp.__version__[0]=='2': mp.style.use('classic')\n",
    "mp.rcParams['figure.dpi'] = default_figdpi\n",
    "mp.rcParams['font.size'] = default_fontsize\n",
    "mp.rcParams['legend.fontsize'] = 'medium'\n",
    "mp.rcParams['figure.max_open_warning'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collective Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If CK is not installed, please install it using:\n",
    "```\n",
    "# pip install ck\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ck.kernel as ck\n",
    "print ('CK version: %s' % ck.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experimental_results(repo_uoa='local', tags='nntest', profiling=False, skip_synthetic_dataset=True):\n",
    "    module_uoa = 'experiment'\n",
    "    r = ck.access({'action':'search', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'tags':tags})\n",
    "    if r['return']>0:\n",
    "        print('Error: %s' % r['error'])\n",
    "        exit(1)\n",
    "    experiments = r['lst']\n",
    "\n",
    "    dfs = []\n",
    "    for experiment in experiments:\n",
    "        data_uoa = experiment['data_uoa']\n",
    "        r = ck.access({'action':'list_points', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'data_uoa':data_uoa})\n",
    "        if r['return']>0:\n",
    "            print('Error: %s' % r['error'])\n",
    "            exit(1)\n",
    "        # Skip experiments if the tags are not in the expected format.\n",
    "        skip = False\n",
    "        library = None\n",
    "        species = None\n",
    "        # Library tags.\n",
    "        library_prefix = 'arm-compute-library-'\n",
    "        library_tags = [ tag[len(library_prefix):] for tag in r['dict']['tags'] if tag.startswith(library_prefix) ]\n",
    "        if len(library_tags)==1:\n",
    "            library = library_tags[0]\n",
    "        else:\n",
    "            skip = True\n",
    "        # Species tags.\n",
    "        species_tags = [ tag for tag in r['dict']['tags'] if tag in ['conv', 'fullyconnected', 'avgpool', 'softmax'] ]\n",
    "        if len(species_tags)==1:\n",
    "            species = species_tags[0]\n",
    "        else:\n",
    "            skip = True\n",
    "        # Check if the experiment should be skipped.\n",
    "        if skip:\n",
    "            print('[Warning] Skipping experiment with tags:')\n",
    "            print(r['dict']['tags'])\n",
    "            continue\n",
    "        for point in r['points']:\n",
    "            point_file_path = os.path.join(r['path'], 'ckp-%s.0001.json' % point)\n",
    "            with open(point_file_path) as point_file:\n",
    "                point_data_raw = json.load(point_file)\n",
    "            characteristics_list = point_data_raw['characteristics_list']\n",
    "            num_repetitions = len(characteristics_list)\n",
    "            platform = model_to_id[point_data_raw['features']['platform']['platform']['model']]\n",
    "            # Shorten the Git hash to 7 symbols to unify across platforms.\n",
    "            if platform=='hikey': # hikey_id\n",
    "                if library_tags[0]=='request-d8f69c13':\n",
    "                    library = 'opencl-18.03-d8f69c1-request'\n",
    "                elif library_tags[0]=='opencl-18.05-0acd60ed-request':\n",
    "                    library = 'opencl-18.05-0acd60e-request'\n",
    "                else:\n",
    "                    library = library_tags[0][:-1]\n",
    "            batch_size = np.int64(point_data_raw['choices']['env'].get('CK_IN_SHAPE_N',-1))\n",
    "            in_shape_n = np.int64(point_data_raw['choices']['env'].get('CK_IN_SHAPE_N',-1))\n",
    "            in_shape_c = np.int64(point_data_raw['choices']['env'].get('CK_IN_SHAPE_C',-1))\n",
    "            in_shape_h = np.int64(point_data_raw['choices']['env'].get('CK_IN_SHAPE_H',-1))\n",
    "            in_shape_w = np.int64(point_data_raw['choices']['env'].get('CK_IN_SHAPE_W',-1))\n",
    "            tuner = point_data_raw['choices']['env'].get('CK_LWS_TUNER_TYPE','NONE')\n",
    "            program = point_data_raw['choices']['data_uoa']\n",
    "            operator = program[:-len('-armcl-opencl')]\n",
    "            dataset_uoa = point_data_raw['choices']['dataset_uoa']\n",
    "            if skip_synthetic_dataset and dataset_uoa.find('synthetic')!=-1: continue\n",
    "            dataset = point_data_raw['choices']['dataset_file']\n",
    "            tensor = dataset[len('shape-'):]\n",
    "            # Obtain column data.\n",
    "            if profiling: # Obtain kernel time from profiling experiments.\n",
    "                index = [\n",
    "                    'platform', 'library', 'operator', 'tensor', 'batch_size', 'kernel', 'repetition_id'\n",
    "                ]\n",
    "                data = []\n",
    "                if point_data_raw['choices'].get('dvdt_prof','')!='':\n",
    "                    data = [\n",
    "                        {\n",
    "                            # features\n",
    "                            'platform': platform,\n",
    "                            'library': library,\n",
    "                            'species': species,\n",
    "                            # choices\n",
    "                            'operator' : operator,\n",
    "                            'tensor' : tensor,\n",
    "                            'batch_size': batch_size,\n",
    "                            'in_shape_n': in_shape_n,\n",
    "                            'in_shape_c': in_shape_c,\n",
    "                            'in_shape_h': in_shape_h,\n",
    "                            'in_shape_w': in_shape_w,\n",
    "                            # statistical repetition\n",
    "                            'repetition_id': repetition_id,\n",
    "                            # runtime characteristics\n",
    "                            'kernel': kernel,\n",
    "                            'time_us': time_us,\n",
    "                            'dvdt_prof': characteristics['run'].get('dvdt_prof', {}),\n",
    "                            'success?': characteristics['run'].get('run_success', 'n/a')\n",
    "                        }\n",
    "                        for (repetition_id, characteristics) in zip(range(num_repetitions), characteristics_list)\n",
    "                        for kernel, time_us in characteristics['run'].get('execution_time_opencl_us',{}).iteritems()\n",
    "                    ]\n",
    "                elif point_data_raw['choices'].get('mali_hwc','')!='':\n",
    "                    data = [\n",
    "                        {\n",
    "                            # features\n",
    "                            'platform': platform,\n",
    "                            'library': library,\n",
    "                            'species': species,                            \n",
    "                            # choices\n",
    "                            'operator' : operator,\n",
    "                            'tensor' : tensor,\n",
    "                            'batch_size': batch_size,\n",
    "                            'in_shape_n': in_shape_n,\n",
    "                            'in_shape_c': in_shape_c,\n",
    "                            'in_shape_h': in_shape_h,\n",
    "                            'in_shape_w': in_shape_w,\n",
    "                            # statistical repetition\n",
    "                            'repetition_id': repetition_id,\n",
    "                            # runtime characteristics\n",
    "                            'kernel': 'n/a',\n",
    "                            'time_us': 0.0,\n",
    "                            'mali_hwc': characteristics['run'].get('mali_hwc', {}),\n",
    "                            'success?': characteristics['run'].get('run_success', 'n/a')\n",
    "                        }\n",
    "                        for (repetition_id, characteristics) in zip(range(num_repetitions), characteristics_list)\n",
    "                    ]\n",
    "                else: # Skip non-profiling experiments.\n",
    "                    continue\n",
    "                # Deal with missing data (resulting from failed runs).\n",
    "                if data==[]:\n",
    "                    print('[Warning] Missing data for: '+\n",
    "                          'platform=%s, dataset=%s, library=%s, batch_size=%d' %\n",
    "                          (platform, dataset, library, batch_size))\n",
    "                    print(point_file_path)\n",
    "                    print\n",
    "                    data = [\n",
    "                        {\n",
    "                            # features\n",
    "                            'platform': platform,\n",
    "                            'library': library,\n",
    "                            'species': species,                            \n",
    "                            # choices\n",
    "                            'operator' : operator,\n",
    "                            'tensor' : tensor,\n",
    "                            'batch_size': batch_size,\n",
    "                            'in_shape_n': in_shape_n,\n",
    "                            'in_shape_c': in_shape_c,\n",
    "                            'in_shape_h': in_shape_h,\n",
    "                            'in_shape_w': in_shape_w,\n",
    "                            # statistical repetition\n",
    "                            'repetition_id': 0,\n",
    "                            # runtime characteristics\n",
    "                            'kernel': 'n/a',\n",
    "                            'time_us': 0.0,\n",
    "                            'success?': 'n/a'\n",
    "                        }\n",
    "                    ]\n",
    "            else: # Obtain wallclock time from validation experiments.\n",
    "                if point_data_raw['choices']['dvdt_prof']=='yes':\n",
    "                    continue # Skip profiling experiments.\n",
    "                data = [\n",
    "                    {\n",
    "                        # features\n",
    "                        'platform': platform,\n",
    "                        'library': library,\n",
    "                        'species': species,                        \n",
    "                        # choices\n",
    "                        'tuner' : tuner,                        \n",
    "                        'operator' : operator,\n",
    "                        'tensor' : tensor,\n",
    "                        'batch_size': batch_size,\n",
    "                        'in_shape_n': in_shape_n,\n",
    "                        'in_shape_c': in_shape_c,\n",
    "                        'in_shape_h': in_shape_h,\n",
    "                        'in_shape_w': in_shape_w,\n",
    "                        # statistical repetition\n",
    "                        'repetition_id': repetition_id,\n",
    "                        # runtime characteristics\n",
    "                        'time_us': 1e6*characteristics['run'].get('execution_time_kernel_1',0.0),\n",
    "                        'success?': characteristics['run'].get('run_success', 'n/a')\n",
    "                    }\n",
    "                    for (repetition_id, characteristics) in zip(range(num_repetitions), characteristics_list)\n",
    "                ]\n",
    "                index = [\n",
    "                    'platform', 'library', 'operator', 'tensor', 'batch_size', 'tuner', 'repetition_id'\n",
    "                ]\n",
    "            # Construct a DataFrame.\n",
    "            df = pd.DataFrame(data)\n",
    "            # Calculate GFLOPS for conv and fullyconnected species. NB: 2 operations per element (multiply and accumulate).\n",
    "            if species=='conv':\n",
    "                flops = 2 * df['tensor'] \\\n",
    "                    .apply(lambda tensor : np.float64(tensor.split('-'))) \\\n",
    "                    .apply(lambda (in_C, H, W, K, out_C, stride, pad) : in_C*out_C*(W/stride)*(H/stride)*K*K) \\\n",
    "                    .values\n",
    "            elif species=='fullyconnected':\n",
    "                flops = 2 * df['tensor'] \\\n",
    "                    .apply(lambda tensor : np.float64(tensor.split('-'))) \\\n",
    "                    .apply(lambda (in_C, in_H, in_W, out_C, out_H, out_W) : (1, in_C*in_H*in_W, out_C*out_H*out_W)) \\\n",
    "                    .apply(lambda (M, K, N): M*K*N) \\\n",
    "                    .values\n",
    "            else:\n",
    "                flops = 0\n",
    "            Gflops = 1e-9 * flops          # 1 Gflops == 1e+9 flops.\n",
    "            time_s = 1e-6 * df['time_us']  # 1 second == 1e+6 microseconds.\n",
    "            df['GFLOPS'] = Gflops / time_s # GFLOPS == Gflops per second.\n",
    "            # Set index.\n",
    "            df = df.set_index(index)\n",
    "            # Append to the list of similarly constructed DataFrames.\n",
    "            dfs.append(df) \n",
    "    if dfs:\n",
    "        # Concatenate all thus constructed DataFrames (i.e. stack on top of each other).\n",
    "        result = pd.concat(dfs)\n",
    "        result = result.sort_index(level=result.index.names)\n",
    "    else:\n",
    "        # Construct a dummy DataFrame which success status can be safely checked.\n",
    "        result = pd.DataFrame(columns=['success?', 'time_us', 'GFLOPS'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot violin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby_level: 'platform', 'operator', 'library' or 'kernel' (with dvdt-prof).\n",
    "# Typically, when creating df_raw, we consider one of the following scenarios:\n",
    "# - different platforms (e.g. hikey and mate), same library (e.g. v18.05), same operator (e.g. fullyconnected)\n",
    "# - different operators (e.g. conv, directconv, winogradconv), same library (e.g. v18.05), same platform (e.g. mate)\n",
    "# - different libraries (e.g. v18.03, v18.05), same operator (e.g. directconv), same platform (e.g. hikey)\n",
    "def plot_violin(df_raw, groupby_level='operator', species=None, metric='time_us',\n",
    "                title=None, figsize=None, fontscale=1.75, legend_loc='upper right',\n",
    "                platform_id=firefly_id, gpu=firefly_gpu, gpu_mhz=firefly_gpu_mhz,\n",
    "                xmin=None, xmax=None, xstep=None):\n",
    "    # Get species.\n",
    "    if not species:\n",
    "        if(df_raw['species']=='fullyconnected').all():\n",
    "            species = 'fullyconnected'\n",
    "        elif(df_raw['species']=='conv').all():\n",
    "            species = 'conv'\n",
    "        elif(df_raw['species']=='avgpool').all():\n",
    "            species = 'avgpool'\n",
    "        elif(df_raw['species']=='softmax').all():\n",
    "            species = 'softmax'\n",
    "        else:\n",
    "            print('Warning: unknown or mixed species')\n",
    "    # Set depending on groupby_level. Drop batch_size (batch_size==1). TODO: support batch_size!=1.\n",
    "    if groupby_level=='platform':\n",
    "        tuples = [ (p,'%s;%s;%s'%(o,l,u),t,r) for (p,l,o,t,b,u,r) in df_raw.index.values ]\n",
    "        names = [ 'platform', 'operator;library;tuner', 'tensor', 'repetition_id' ]\n",
    "        hue_levels = 'operator;library;tuner'\n",
    "        palette = 'summer'\n",
    "    elif groupby_level=='operator':\n",
    "        tuples = [ (o,'%s;%s;%s'%(p,l,u),t,r) for (p,l,o,t,b,u,r) in df_raw.index.values ]\n",
    "        names = [ 'operator', 'platform;library;tuner', 'tensor', 'repetition_id' ]\n",
    "        hue_levels = 'platform;library;tuner'\n",
    "        palette = 'autumn'\n",
    "    elif groupby_level=='library':\n",
    "        tuples = [ (l,'%s;%s;%s'%(o,p,u),t,r) for (p,l,o,t,b,u,r) in df_raw.index.values ]\n",
    "        names = [ 'library', 'operator;platform;tuner', 'tensor', 'repetition_id' ]\n",
    "        hue_levels = 'operator;platform;tuner'\n",
    "        palette = 'spring'\n",
    "    elif groupby_level=='kernel': # no tuner\n",
    "        tuples = [ (k,'%s;%s;%s'%(o,p,l),t,r) for (p,l,o,t,b,k,r) in df_raw.index.values ]\n",
    "        names = [ 'kernel', 'operator;platform;library', 'tensor', 'repetition_id' ]\n",
    "        hue_levels = 'operator;platform;library'\n",
    "        palette = 'winter'\n",
    "    else:\n",
    "        print('Error: unsupported groupby_level=%s' % groupby_level)\n",
    "        exit(1)\n",
    "    # Create a new DataFrame using the index settings above.\n",
    "    df_violin = pd.DataFrame(data=df_raw[metric].values, columns=[metric],\n",
    "                             index=pd.MultiIndex.from_tuples(tuples=tuples, names=names)).sort_index()\n",
    "    # Set style.\n",
    "    sb.set_style('whitegrid')\n",
    "    sb.set_palette(palette)\n",
    "    fontsize = default_fontsize*fontscale\n",
    "    if metric=='time_us':\n",
    "        xlabel = 'Operator execution time (microseconds)'\n",
    "    elif metric=='GFLOPS':\n",
    "        xlabel = 'Operator GFLOPS (billion single-precision floating-point operations per second)'\n",
    "    ylabel = 'Tensor shape'\n",
    "    if species=='fullyconnected':\n",
    "        ylabel += ' (in_C, in_H, in_W, out_C, out_H, out_W)'\n",
    "    elif species=='conv':\n",
    "        ylabel += ' (in_C, H, W, K, out_C, stride, pad)'\n",
    "    elif species=='avgpool':\n",
    "        ylabel += ' (C, H, W, K, stride)'\n",
    "    elif species=='softmax':\n",
    "        ylabel += ' (C, H, W)'\n",
    "    if not figsize:\n",
    "        num_groupby_values = len(df_raw.index.get_level_values(level=groupby_level).unique())\n",
    "        # TODO: num_kernels\n",
    "        num_platforms = len(df_raw.index.get_level_values(level='platform').unique())\n",
    "        num_libraries = len(df_raw.index.get_level_values(level='library').unique())\n",
    "        num_operators = len(df_raw.index.get_level_values(level='operator').unique())\n",
    "        num_tensors = len(df_raw.index.get_level_values(level='tensor').unique())\n",
    "        num_tuners = len(df_raw.index.get_level_values(level='tuner').unique())\n",
    "        figheight = num_platforms * num_libraries * num_operators * num_tensors * num_tuners / num_groupby_values\n",
    "        figsize = (default_figwidth, figheight)\n",
    "    # For each unique groupby value.\n",
    "    groupby_values = df_violin.index.get_level_values(level=groupby_level).unique()\n",
    "    for groupby_value in groupby_values:\n",
    "        df_violin_loc = df_violin.loc[groupby_value].reset_index()\n",
    "        fig = plt.figure(figsize=figsize, dpi=default_figdpi)\n",
    "        ax = fig.gca()\n",
    "        sb.violinplot(ax=ax, data=df_violin_loc, x=metric, y='tensor', inner='point', split=False, saturation=0.8,\n",
    "                      hue=hue_levels, fontscale=fontscale)\n",
    "        # Title.\n",
    "        if title:\n",
    "            groupby_title = '%s: %s=%s' % (title, groupby_level, groupby_value)\n",
    "        else:\n",
    "            if groupby_level=='platform':\n",
    "                groupby_title = '%s (GPU: %s @ %d MHz)' % (id_to_name[platform_id], gpu, gpu_mhz)\n",
    "            else:\n",
    "                groupby_title = '%s=%s' % (groupby_level, groupby_value)\n",
    "        ax.set_title(groupby_title, fontsize=fontsize)\n",
    "        # X axis.\n",
    "        if not xstep: xstep = 1000\n",
    "        if not xmin: xmin = np.int64(df_violin_loc[metric].min())\n",
    "        if not xmax: xmax = np.int64(df_violin_loc[metric].max()) // xstep * xstep + xstep\n",
    "        ax.set_xlim([xmin, xmax])\n",
    "        ax.set_xticks(range(0, xmax+1, xstep))\n",
    "        ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "        # Y axis.\n",
    "        ax.set_ylabel(ylabel, fontsize=fontsize)\n",
    "        ax.tick_params(axis='y', labelsize=fontsize)\n",
    "        # Vertical lines between groups of violins.\n",
    "        for y in ax.get_yticks():\n",
    "            ax.hlines(y=y+0.5, xmin=0, xmax=xmax, linestyles='dotted', colors='black')\n",
    "        # Legend location.\n",
    "        ax.legend(loc=legend_loc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speedup(df, baseline_levels='platform', baseline_values=firefly_id,\n",
    "                 title=None, xmax=None, figsize=None, fontsize=default_fontsize,\n",
    "                 legend_loc='lower right'):\n",
    "    if not title: title = '%s=%s' % (str(baseline_levels), str(baseline_values))\n",
    "    if not figsize:\n",
    "        num_rows = len(df.index)\n",
    "        num_tensors = len(df.index.get_level_values(level='tensor').unique())\n",
    "        fig_height = 2 * num_rows / num_tensors\n",
    "        figsize=[default_figwidth, fig_height]\n",
    "    df_ = df.unstack(baseline_levels)\n",
    "    df_speedup = 1. / df_.divide(df_[baseline_values], axis=0).stack(baseline_levels)\n",
    "    # Plot the speedups.\n",
    "    axes = pd.DataFrame(data=df_speedup, columns=['speedup (x)']) \\\n",
    "        .reorder_levels(['tensor', 'platform', 'library', 'operator', 'batch_size', 'tuner']) \\\n",
    "        .groupby(level=['tensor']) \\\n",
    "        .plot(kind='barh', title=title, stacked=False, width=0.8, grid=True, legend=True,\n",
    "              xlim=[0,xmax], figsize=figsize, fontsize=default_fontsize, colormap=cm.autumn)\n",
    "    # Annotate the bars with the speedups rounded to one digit after the decimal point.\n",
    "    for ax in axes:\n",
    "        ax.set_title(title, fontsize=fontsize)\n",
    "        ax.tick_params(axis='x', labelsize=fontsize)\n",
    "        ax.legend(loc=legend_loc)\n",
    "        for patch in ax.patches:\n",
    "            text = '{0:.1f}x'.format(patch.get_width())\n",
    "            ax.annotate(text, (patch.get_width()*1.01, patch.get_y()*1.01), fontsize=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_mobilenets_baseline\"></a>\n",
    "## `MobileNets-v1-1.0-224` (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_mobilenets_baseline_setup\"></a>\n",
    "### Experimental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ ck run nntest:conv-armcl-opencl \\\n",
    "--dataset_uoa=tensor-conv-mobilenets-v1-1.0-224 \\\n",
    "--timestamp=mobilenets-v1-1.0-224-firefly-tuner-none \\\n",
    "--repetitions=10 --iterations=1 \\\n",
    "--env.CK_LWS_TUNER_TYPE=NONE\n",
    "\n",
    "$ ck run nntest:directconv-armcl-opencl \\\n",
    "--dataset_uoa=tensor-conv-mobilenets-v1-1.0-224 \\\n",
    "--timestamp=mobilenets-v1-1.0-224-firefly-tuner-none \\\n",
    "--repetitions=10 --iterations=1 \\\n",
    "--env.CK_LWS_TUNER_TYPE=NONE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ck list $repo_uoa:experiment:nntest*mobilenets-v1-1.0-224-firefly-tuner-none | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ ck run nntest:conv-armcl-opencl \\\n",
    "--dataset_uoa=tensor-conv-mobilenets-v1-1.0-224 \\\n",
    "--timestamp=mobilenets-v1-1.0-224-firefly-tuner-default \\\n",
    "--repetitions=10 --iterations=1 \\\n",
    "--env.CK_LWS_TUNER_TYPE=DEFAULT\n",
    "\n",
    "$ ck run nntest:directconv-armcl-opencl \\\n",
    "--dataset_uoa=tensor-conv-mobilenets-v1-1.0-224 \\\n",
    "--timestamp=mobilenets-v1-1.0-224-firefly-tuner-default \\\n",
    "--repetitions=10 --iterations=1 \\\n",
    "--env.CK_LWS_TUNER_TYPE=DEFAULT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ck list $repo_uoa:experiment:nntest*mobilenets-v1-1.0-224-firefly-tuner-default | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_mobilenets_baseline_experiments_all\"></a>\n",
    "### All experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_experimental_results(repo_uoa=repo_uoa, tags='conv', profiling=False)\n",
    "display_in_full(df[['time_us','GFLOPS','success?']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_mobilenets_baseline_experiments_failed\"></a>\n",
    "### Failed experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failed = df[df['success?']!='yes']\n",
    "df = df[df['success?']=='yes']\n",
    "display_in_full(df_failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_mobilenets_baseline_plot_platform_us\"></a>\n",
    "### Plot by platform (microseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin(df_raw=df, groupby_level='platform', xstep=1000, xmax=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_mobilenets_baseline_plot_platform_gflops\"></a>\n",
    "### Plot by platform (GFLOPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin(df_raw=df, groupby_level='platform', metric='GFLOPS', xstep=1, xmax=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_mobilenets_baseline_plot_speedup\"></a>\n",
    "### Plot speedup over untuned direct convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use median (50% percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df['time_us'].groupby(level=df.index.names[:-1]).describe()['50%']\n",
    "plot_speedup(median, xmax=8.0, legend_loc='upper right',\n",
    "             baseline_levels=('platform', 'library', 'operator', 'tuner'),\n",
    "             baseline_values=('firefly', 'opencl-18.05-b3a371b', 'directconv', 'NONE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "minimum = df['time_us'].groupby(level=df.index.names[:-1]).min()\n",
    "plot_speedup(minimum, xmax=8.0, legend_loc='upper right',\n",
    "             baseline_levels=('platform', 'library', 'operator', 'tuner'),\n",
    "             baseline_values=('firefly', 'opencl-18.05-b3a371b', 'directconv', 'NONE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that DEFAULT is always better than NONE.\n",
    "best_tuner = minimum.groupby(level=minimum.index.names[:-1]).idxmin()\n",
    "minimum[best_tuner]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain optimal schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = pd.DataFrame(minimum)\n",
    "display_in_full(df_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_tuner = df_min.loc[best_tuner]\n",
    "display_in_full(df_best_tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_operator = df_best_tuner.swaplevel('tuner', 'operator')\n",
    "display_in_full(df_best_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: simplify.\n",
    "best_operator = df_best_operator['time_us'].groupby(level=df_best_operator.index.names[:-1]).idxmin()\n",
    "df_best_operator = df_best_operator \\\n",
    "    .loc[best_operator] \\\n",
    "    .swaplevel('operator', 'tuner')\n",
    "display_in_full(df_best_operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor '512-14-14-1-512-1-0' is repeated 5 times.\n",
    "# TODO: just index using this tensor.\n",
    "index_of_repeated_layer = (firefly_id, 'opencl-18.05-b3a371b', 'conv', '512-14-14-1-512-1-0', 1, 'DEFAULT')\n",
    "df_best_operator.sum() + 4 * df_best_operator.loc[index_of_repeated_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_mobilenets_baseline_profiler\"></a>\n",
    "## `MobileNets-v1-1.0-224` (\"baseline\"): profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ ck run nntest:conv-armcl-opencl --dvdt_prof \\\n",
    "--dataset_uoa=tensor-conv-mobilenets-v1-1.0-224 \\\n",
    "--timestamp=mobilenets-v1-1.0-224-firefly-profiler \\\n",
    "--repetitions=10 --iterations=1 \\\n",
    "--env.CK_LWS_TUNER_TYPE=NONE\n",
    "\n",
    "$ ck run nntest:directconv-armcl-opencl --dvdt_prof \\\n",
    "--dataset_uoa=tensor-conv-mobilenets-v1-1.0-224 \\\n",
    "--timestamp=mobilenets-v1-1.0-224-firefly-profiler \\\n",
    "--repetitions=10 --iterations=1 \\\n",
    "--env.CK_LWS_TUNER_TYPE=NONE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ck list $repo_uoa:experiment:nntest*mobilenets-v1-1.0-224-firefly-profiler | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_mobilenets_reduced\"></a>\n",
    "## `MobileNets-v1-0.75-160` (\"reduced\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
