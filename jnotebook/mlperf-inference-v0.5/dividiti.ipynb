{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate [dividiti](http://dividiti.com)'s submissions to [MLPerf Inference v0.5](https://github.com/mlperf/inference/tree/master/v0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook covers [dividiti](http://dividiti.com)'s submissions to [MLPerf Inference v0.5](https://github.com/mlperf/inference/tree/master/v0.5). It validates that experimental data obtained via automated, portable and reproducible [Collective Knowledge](http://cknowledge.org) workflows conforms to [General MLPerf Submission Rules](https://github.com/mlperf/policies/blob/master/submission_rules.adoc)\n",
    "and [MLPerf Inference Rules](https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc), including runnning the official [`submission_checker.py`](https://github.com/mlperf/inference/blob/master/v0.5/tools/submission/submission-checker.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A live version of this Jupyter Notebook can be viewed [here](https://nbviewer.jupyter.org/urls/dl.dropbox.com/s/1xlv5oacgobrfd4/mlperf-inference-v0.5-dividiti.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Overview](#overview)\n",
    "1. [Includes](#includes)\n",
    "1. [System templates](#templates)\n",
    "  1. [Firefly RK3399](#templates_firefly)\n",
    "  1. [Linaro HiKey960](#templates_hikey960)\n",
    "  1. [Huawei Mate 10 Pro](#templates_mate10pro)\n",
    "  1. [Raspberry Pi 4](#templates_rpi4)\n",
    "  1. [HP Z640](#templates_velociti)\n",
    "  1. [Default](#templates_default)\n",
    "1. [Systems](#systems)\n",
    "1. [Implementations](#implementations)\n",
    "1. [Get the experimental data](#get)\n",
    "  1. [Image Classification - Closed](#get_image_classification_closed)\n",
    "  1. [Image Classification - Open](#get_image_classification_open)\n",
    "  1. [Object Detection - Open](#get_object_detection_open)\n",
    "1. [Generate the submission checklist](#checklist)\n",
    "1. [Check the experimental data](#check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"includes\"></a>\n",
    "## Includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "from shutil import copy2\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scientific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some of the scientific packages are missing, please install them using:\n",
    "```\n",
    "# python3 -m pip install jupyter pandas numpy matplotlib seaborn --user\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colormap = cm.autumn\n",
    "default_fontsize = 16\n",
    "default_barwidth = 0.8\n",
    "default_figwidth = 24\n",
    "default_figheight = 3\n",
    "default_figdpi = 200\n",
    "default_figsize = [default_figwidth, default_figheight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp.__version__[0]=='2': mp.style.use('classic')\n",
    "mp.rcParams['figure.max_open_warning'] = 200\n",
    "mp.rcParams['figure.dpi'] = default_figdpi\n",
    "mp.rcParams['font.size'] = default_fontsize\n",
    "mp.rcParams['legend.fontsize'] = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Do not hardcode - locate via CK.\n",
    "pythonpath_coco = '/home/anton/CK_TOOLS/tool-coco-master-gcc-8.3.0-compiler.python-3.6.9-linux-64/'\n",
    "sys.path.append(pythonpath_coco)\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If CK is not installed, please install it using:\n",
    "```\n",
    "# python -m pip install ck\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ck.kernel as ck\n",
    "print ('CK version: %s' % ck.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"templates\"></a>\n",
    "## System templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"templates_firefly\"></a>\n",
    "### [Firefly-RK3399](http://en.t-firefly.com/product/rk3399/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firefly = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"Firefly-RK3399 (firefly)\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Arm Cortex-A72 MP2 (big); Arm Cortex-A53 MP4 (LITTLE)\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"2 (big); 4 (LITTLE)\",\n",
    "    \"host_processor_frequency\": \"1800 MHz (big), 1400 MHz (LITTLE)\",\n",
    "    \"host_processor_caches\": \"L1I$ 48 KiB, L1D$ 32 KiB, L2$ 1 MiB (big); L1I$ 32 KiB, L1D$ 32 KiB, L2$ 512 KiB (LITTLE)\",\n",
    "    \"host_memory_configuration\": \"-\",\n",
    "    \"host_memory_capacity\": \"4 GiB\",\n",
    "    \"host_storage_capacity\": \"128 GiB\",\n",
    "    \"host_storage_type\": \"SanDisk Extreme microSD\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"1\",\n",
    "    \"accelerator_model_name\": \"Arm Mali-T860 MP4\",\n",
    "    \"accelerator_frequency\": \"800 MHz\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"4 GiB (shared with host)\",\n",
    "    \"accelerator_memory_configuration\": \"-\",\n",
    "    \"accelerator_on-chip_memories\": \"-\",\n",
    "    \"cooling\": \"on-board fan\",\n",
    "    \"hw_notes\": \"http://en.t-firefly.com/product/rk3399/; http://opensource.rock-chips.com/wiki_RK3399\",\n",
    "\n",
    "    \"framework\": \"\",\n",
    "    \"operating_system\": \"Ubuntu 16.04.6 LTS; kernel 4.4.77 #554 (Thu Nov 30 11:30:11 HKT 2017)\",\n",
    "    \"other_software_stack\": \"GCC 7.4.0; Python 3.5.2; OpenCL driver 1.2 v1.r13p0-00rel0-git(a4271c9).31ba04af2d3c01618138bef3aed66c2c\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"templates_hikey960\"></a>\n",
    "### [Linaro HiKey960](https://www.96boards.org/product/hikey960/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hikey960 = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"Linaro HiKey960 (hikey960)\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Arm Cortex-A73 MP4 (big); Arm Cortex-A53 MP4 (LITTLE)\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"4 (big); 4 (LITTLE)\",\n",
    "    \"host_processor_frequency\": \"2362 MHz (big), 1844 MHz (LITTLE)\",\n",
    "    \"host_processor_caches\": \"L1I$ 256=4x64 KiB, L1D$ 256=4x64 KiB, L2$ 2 MiB (big); L1I$ 128=4x32 KiB, L1D$ 128=4x32 KiB, L2$ 1 MiB (LITTLE)\",\n",
    "    \"host_memory_configuration\": \"-\",\n",
    "    \"host_memory_capacity\": \"3 GiB\",\n",
    "    \"host_storage_capacity\": \"128 GiB\",\n",
    "    \"host_storage_type\": \"SanDisk Extreme microSD\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"1\",\n",
    "    \"accelerator_model_name\": \"Arm Mali-G71 MP8\",\n",
    "    \"accelerator_frequency\": \"800 MHz\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"3 GiB (shared with host)\",\n",
    "    \"accelerator_memory_configuration\": \"-\",\n",
    "    \"accelerator_on-chip_memories\": \"-\",\n",
    "    \"cooling\": \"small external fan\",\n",
    "    \"hw_notes\": \"http://www.hisilicon.com/en/Products/ProductList/Kirin\",\n",
    "\n",
    "    \"framework\": \"\",\n",
    "    \"operating_system\": \"Debian 9; kernel 4.19.5-hikey #26 (Thu Aug 22 07:58:35 UTC 2019)\",\n",
    "    \"other_software_stack\": \"GCC 7.4.0; Python 3.5.3; OpenCL driver 2.0 v1.r16p0\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"templates_mate10pro\"></a>\n",
    "### Huawei Mate 10 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mate10pro = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"Huawei Mate 10 Pro (mate10pro)\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Arm Cortex-A73 MP4 (big); Arm Cortex-A53 MP4 (LITTLE)\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"4 (big); 4 (LITTLE)\",\n",
    "    \"host_processor_frequency\": \"2360 MHz (big), 1800 MHz (LITTLE)\",\n",
    "    \"host_processor_caches\": \"L1I$ 256=4x64 KiB, L1D$ 256=4x64 KiB, L2$ 2 MiB (big); L1I$ 128=4x32 KiB, L1D$ 128=4x32 KiB, L2$ 1 MiB (LITTLE)\",\n",
    "    \"host_memory_configuration\": \"-\",\n",
    "    \"host_memory_capacity\": \"6 GiB\",\n",
    "    \"host_storage_capacity\": \"128 GiB\",\n",
    "    \"host_storage_type\": \"Flash\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"1\",\n",
    "    \"accelerator_model_name\": \"Arm Mali-G72 MP12\",\n",
    "    \"accelerator_frequency\": \"850 MHz\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"6 GiB (shared with host)\",\n",
    "    \"accelerator_memory_configuration\": \"-\",\n",
    "    \"accelerator_on-chip_memories\": \"-\",\n",
    "    \"cooling\": \"phone case\",\n",
    "    \"hw_notes\": \"https://en.wikichip.org/wiki/hisilicon/kirin/970\",\n",
    "\n",
    "    \"framework\": \"\",\n",
    "    \"operating_system\": \"Android 9.1.0.300(C782E5R1P11); kernel 4.9.148 (Sat Jun 29 20:41:06 CST 2019)\",\n",
    "    \"other_software_stack\": \"Android NDK 17c (LLVM 6.0.2); OpenCL driver 2.0 v1.r14p0-00cet0.0416641283c5d6e2d53c163d0ca99357\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"templates_rpi4\"></a>\n",
    "### Raspberry Pi 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpi4 = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"Raspberry Pi 4 (rpi4)\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Arm Cortex-A72 MP4\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"4\",\n",
    "    \"host_processor_frequency\": \"1500 MHz\",\n",
    "    \"host_processor_caches\": \"L1I$ 128=4x32 KiB, L1D$ 128=4x32 KiB, L2$ 1 MiB\",\n",
    "    \"host_memory_configuration\": \"-\",\n",
    "    \"host_memory_capacity\": \"4 GiB\",\n",
    "    \"host_storage_capacity\": \"128 GiB\",\n",
    "    \"host_storage_type\": \"SanDisk Extreme Pro microSD\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"0\",\n",
    "    \"accelerator_model_name\": \"-\",\n",
    "    \"accelerator_frequency\": \"-\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"-\",\n",
    "    \"accelerator_memory_configuration\": \"-\",\n",
    "    \"accelerator_on-chip_memories\": \"-\",\n",
    "    \"cooling\": \"http://www.raspberrypiwiki.com/index.php/Armor_Case_B\",\n",
    "    \"hw_notes\": \"https://www.raspberrypi.org/products/raspberry-pi-4-model-b/specifications/\",\n",
    "\n",
    "    \"framework\": \"\",\n",
    "    \"operating_system\": \"Raspbian Buster (Debian 10); kernel 4.19.66-v7l+ #1253 (Thu Aug 15 12:02:08 BST 2019)\",\n",
    "    \"other_software_stack\": \"GCC 8.3.0; Python 3.7.3\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"templates_velociti\"></a>\n",
    "### HP Z640 workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velociti = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"HP Z640 G1X62EA workstation (velociti)\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Intel Xeon CPU E5-2650 v3\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"10\",\n",
    "    \"host_processor_frequency\": \"2300 MHz (base); 3000 MHz (turbo)\",\n",
    "    \"host_processor_caches\": \"L1I$ 10x32 KiB, L1D$ 10x32 KiB; L2$ 10x256 KiB; L3$ 25 MiB\",\n",
    "    \"host_memory_configuration\": \"DDR4 (max bandwidth 68 GB/s)\",\n",
    "    \"host_memory_capacity\": \"32 GiB\",\n",
    "    \"host_storage_capacity\": \"512 GiB\",\n",
    "    \"host_storage_type\": \"SSD\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"1\",\n",
    "    \"accelerator_model_name\": \"NVIDIA GeForce GTX 1080\",\n",
    "    \"accelerator_frequency\": \"1607 MHz (base); 1733 MHz (boost)\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"8 GiB\",\n",
    "    \"accelerator_memory_configuration\": \"GDDR5X (max bandwidth 320 GB/s)\",\n",
    "    \"accelerator_on-chip_memories\": \"20x48 KiB\",\n",
    "    \"cooling\": \"standard\",\n",
    "    \"hw_notes\": \"The Intel CPU has reached its end-of-life (EOL). http://h20195.www2.hp.com/v2/default.aspx?cc=ie&lc=en&oid=7528701; https://ark.intel.com/products/81705/Intel-Xeon-Processor-E5-2650-v3-25M-Cache-2_30-GHz; http://www.cpu-world.com/CPUs/Xeon/Intel-Xeon%20E5-2650%20v3.html; http://www.geforce.co.uk/hardware/10series/geforce-gtx-1080/\",\n",
    "    \n",
    "    \"framework\": \"TensorFlow v1.14\",\n",
    "    \"operating_system\": \"Ubuntu 16.04.6 LTS; kernel 4.4.0-112-generic #135-Ubuntu SMP (Fri Jan 19 11:48:36 UTC 2018)\",\n",
    "    \"other_software_stack\": \"Driver 430.50; CUDA 10.1; TensorRT 5.1.5; Docker 19.03.3 (build a872fc2); GCC 7.4.0; Python 3.5.2\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"templates_default\"></a>\n",
    "### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default `system_desc_id.json` (to catch uninitialized descriptions)\n",
    "default_system_json = {\n",
    "    \"division\": \"reqired\",\n",
    "    \"submitter\": \"required\",\n",
    "    \"status\": \"required\",\n",
    "    \"system_name\": \"required\",\n",
    "\n",
    "    \"number_of_nodes\": \"required\",\n",
    "    \"host_processor_model_name\": \"required\",\n",
    "    \"host_processors_per_node\": \"required\",\n",
    "    \"host_processor_core_count\": \"required\",\n",
    "    \"host_processor_frequency\": \"\",\n",
    "    \"host_processor_caches\": \"\",\n",
    "    \"host_memory_configuration\": \"\",\n",
    "    \"host_memory_capacity\": \"required\",\n",
    "    \"host_storage_capacity\": \"required\",\n",
    "    \"host_storage_type\": \"required\",\n",
    "    \"host_processor_interconnect\": \"\",\n",
    "    \"host_networking\": \"\",\n",
    "    \"host_networking_topology\": \"\",\n",
    "\n",
    "    \"accelerators_per_node\": \"required\",\n",
    "    \"accelerator_model_name\": \"required\",\n",
    "    \"accelerator_frequency\": \"\",\n",
    "    \"accelerator_host_interconnect\": \"\",\n",
    "    \"accelerator_interconnect\": \"\",\n",
    "    \"accelerator_interconnect_topology\": \"\",\n",
    "    \"accelerator_memory_capacity\": \"required\",\n",
    "    \"accelerator_memory_configuration\": \"\",\n",
    "    \"accelerator_on-chip_memories\": \"\",\n",
    "    \"cooling\": \"\",\n",
    "    \"hw_notes\": \"\",\n",
    "\n",
    "    \"framework\": \"required\",\n",
    "    \"operating_system\": \"required\",\n",
    "    \"other_software_stack\": \"required\",\n",
    "    \"sw_notes\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"systems\"></a>\n",
    "## Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate division_systems dictionary.\n",
    "division_systems = {}\n",
    "\n",
    "platform_templates = {\n",
    "    'firefly'   : firefly,\n",
    "    'hikey960'  : hikey960,\n",
    "    'mate10pro' : mate10pro,\n",
    "    'rpi4'      : rpi4,\n",
    "    'velociti'  : velociti\n",
    "}\n",
    "\n",
    "divisions = [ 'open', 'closed' ]\n",
    "platforms = [ 'firefly', 'hikey960', 'mate10pro', 'rpi4', 'velociti' ]\n",
    "for division in divisions:\n",
    "    for platform in platforms:\n",
    "        if platform == 'velociti':\n",
    "            libraries = [ 'tensorflow-v1.14' ]\n",
    "        elif platform == 'mate10pro':\n",
    "            libraries = [ 'tflite-v1.13', 'armnn-v19.08' ]\n",
    "        else:\n",
    "            libraries = [ 'tflite-v1.15', 'armnn-v19.08' ]\n",
    "        for library in libraries:\n",
    "            if library == 'armnn-v19.08':\n",
    "                if platform == 'rpi4':\n",
    "                    backends = [ 'neon' ]\n",
    "                else:\n",
    "                    backends = [ 'neon', 'opencl' ]\n",
    "                library_backends = [ library+'-'+backend for backend in backends ]\n",
    "            elif library == 'tensorflow-v1.14':\n",
    "                backends = [ 'cpu', 'cuda', 'tensorrt', 'tensorrt-dynamic' ]\n",
    "                library_backends = [ library+'-'+backend for backend in backends ]\n",
    "            else:\n",
    "                library_backends = [ library ]\n",
    "            for library_backend in library_backends:\n",
    "                division_system = division+'-'+platform+'-'+library_backend\n",
    "                frameworks = {\n",
    "                    'armnn-v19.08-opencl' : 'ArmNN v19.08 (OpenCL)',\n",
    "                    'armnn-v19.08-neon' : 'ArmNN v19.08 (Neon)',\n",
    "                    'tflite-v1.13': 'TFLite v1.13.1',\n",
    "                    'tflite-v1.15': 'TFLite v1.15.0-rc2',\n",
    "                    'tensorflow-v1.14-cpu': 'TensorFlow v1.14 (CPU)',\n",
    "                    'tensorflow-v1.14-cuda': 'TensorFlow v1.14 (CUDA)',\n",
    "                    'tensorflow-v1.14-tensorrt': 'TensorFlow v1.14 (TensorRT-static)',\n",
    "                    'tensorflow-v1.14-tensorrt-dynamic': 'TensorFlow v1.14 (TensorRT-dynamic)',\n",
    "                }\n",
    "                template = deepcopy(platform_templates[platform])\n",
    "                template.update({\n",
    "                    'division'  : division,\n",
    "                    'submitter' : 'dividiti', # 'dividiti' if platform != 'velociti' else 'dividiti, Politecnico di Milano'\n",
    "                    'status'    : 'available' if library_backend != 'tensorflow-v1.14-cpu' else 'RDI',\n",
    "                    'framework' : frameworks[library_backend]\n",
    "                })\n",
    "                if (not library_backend.startswith('tensorflow') and not library_backend.endswith('opencl')) \\\n",
    "                or library_backend.endswith('cpu'):\n",
    "                    template.update({\n",
    "                        'accelerator_frequency' : '-',\n",
    "                        'accelerator_memory_capacity' : '-',\n",
    "                        'accelerator_memory_configuration': '-',\n",
    "                        'accelerator_model_name' : '-',\n",
    "                        'accelerator_on-chip_memories': '-',\n",
    "                        'accelerators_per_node' : '0',\n",
    "                    })\n",
    "                division_systems[division_system] = template\n",
    "                print(\"=\" * 100)\n",
    "                print(division_system)\n",
    "                print(\"=\" * 100)\n",
    "                pprint(template)\n",
    "                print(\"-\" * 100)\n",
    "                print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"implementations\"></a>\n",
    "## Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate implementation_benchmarks dictionary.\n",
    "implementation_benchmarks = {}\n",
    "\n",
    "# Default `system_desc_id_imp.json` (to catch uninitialized descriptions)\n",
    "default_implementation_benchmark_json = {\n",
    "    \"input_data_types\": \"required\",\n",
    "    \"retraining\": \"required\",\n",
    "    \"starting_weights_filename\": \"required\",\n",
    "    \"weight_data_types\": \"required\",\n",
    "    \"weight_transformations\": \"required\"\n",
    "}\n",
    "\n",
    "# For each image classification implementation.\n",
    "for implementation in [ 'image-classification-tflite', 'image-classification-armnn-tflite' ]:\n",
    "    # Add MobileNet.\n",
    "    implementation_mobilenet = implementation+'-'+'mobilenet'\n",
    "    implementation_benchmarks[implementation_mobilenet] = {\n",
    "        \"input_data_types\": \"fp32\",\n",
    "        \"weight_data_types\": \"fp32\",\n",
    "        \"retraining\": \"no\",\n",
    "        \"starting_weights_filename\": \"https://zenodo.org/record/2269307/files/mobilenet_v1_1.0_224.tgz\",\n",
    "        \"weight_transformations\": \"TFLite\"\n",
    "    }\n",
    "    # Add MobileNet quantized.\n",
    "    implementation_mobilenet_quantized = implementation+'-'+'mobilenet-quantized'\n",
    "    implementation_benchmarks[implementation_mobilenet_quantized] = {\n",
    "        \"input_data_types\": \"uint8\",\n",
    "        \"weight_data_types\": \"uint8\",\n",
    "        \"retraining\": \"no\",\n",
    "        \"starting_weights_filename\": \"https://zenodo.org/record/2269307/files/mobilenet_v1_1.0_224_quant.tgz\",\n",
    "        \"weight_transformations\": \"TFLite\"\n",
    "    }\n",
    "    # Add ResNet.\n",
    "    implementation_resnet = implementation+'-'+'resnet'\n",
    "    implementation_benchmarks[implementation_resnet] = {\n",
    "        \"input_data_types\": \"fp32\",\n",
    "        \"weight_data_types\": \"fp32\",\n",
    "        \"retraining\": \"no\",\n",
    "        \"starting_weights_filename\": \"https://zenodo.org/record/2535873/files/resnet50_v1.pb\",\n",
    "        \"weight_transformations\": \"TF -> TFLite\"\n",
    "    }\n",
    "    # Add any MobileNets-v1,v2 model.\n",
    "    def add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution, quantized=False):\n",
    "        base_url = 'https://zenodo.org/record/2269307/files' if version == 1 else 'https://zenodo.org/record/2266646/files'\n",
    "        url = '{}/mobilenet_v{}_{}_{}{}.tgz'.format(base_url, version, multiplier, resolution, '_quant' if quantized else '')\n",
    "        benchmark = 'mobilenet-v{}-{}-{}{}'.format(version, multiplier, resolution, '-quantized' if quantized else '')\n",
    "        if quantized and (version != 1 or implementation != 'image-classification-tflite'):\n",
    "            return\n",
    "        if implementation == 'image-classification-tflite':\n",
    "            weights_transformations = 'TFLite'\n",
    "        elif implementation == 'image-classification-armnn-tflite':\n",
    "            weights_transformations = 'TFLite -> ArmNN'\n",
    "        else:\n",
    "            raise \"Unknown implementation '%s'!\" % implementation\n",
    "        implementation_benchmark = implementation+'-'+benchmark\n",
    "        implementation_benchmarks[implementation_benchmark] = {\n",
    "            \"input_data_types\": \"uint8\" if quantized else \"fp32\",\n",
    "            \"weight_data_types\": \"uint8\" if quantized else \"fp32\",\n",
    "            \"retraining\": \"no\",\n",
    "            \"starting_weights_filename\": url,\n",
    "            \"weight_transformations\": weights_transformations\n",
    "        }\n",
    "        return\n",
    "    # MobileNet-v1.\n",
    "    version = 1\n",
    "    for multiplier in [ 1.0, 0.75, 0.5, 0.25 ]:\n",
    "        for resolution in [ 224, 192, 160, 128 ]:\n",
    "            add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution, quantized=False)\n",
    "            add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution, quantized=True)\n",
    "    # MobileNet-v2.\n",
    "    version = 2\n",
    "    for multiplier in [ 1.0, 0.75, 0.5, 0.35 ]:\n",
    "        for resolution in [ 224, 192, 160, 128, 96 ]:\n",
    "            add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution)\n",
    "    add_implementation_mobilenet(implementation_benchmarks, version=2, multiplier=1.3, resolution=224)\n",
    "    add_implementation_mobilenet(implementation_benchmarks, version=2, multiplier=1.4, resolution=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection_benchmarks = {\n",
    "    'rcnn-nas-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-NAS lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1200,\n",
    "        \"height\" : 1200,\n",
    "    },\n",
    "    'rcnn-resnet50-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-ResNet50 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-resnet101-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-ResNet101 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-inception-resnet-v2-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-Inception-ResNet-v2 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-inception-v2' : {\n",
    "        \"name\" : \"Faster-RCNN Inception-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'ssd-inception-v2' : {\n",
    "        \"name\" : \"SSD-Inception-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "    },\n",
    "    'ssd-mobilenet-v1-quantized-mlperf' : {\n",
    "        \"name\" : \"MLPerf SSD-MobileNet\",\n",
    "        \"url\" : \"https://zenodo.org/record/3361502/files/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "        \"provenance\" : \"Google\",\n",
    "    },\n",
    "    'ssd-mobilenet-v1-non-quantized-mlperf' : {\n",
    "        \"name\" : \"MLPerf SSD-MobileNet quantized\",\n",
    "        \"url\" : \"https://zenodo.org/record/3252084/files/mobilenet_v1_ssd_8bit_finetuned.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "        \"provenance\" : \"Habana\"\n",
    "    },\n",
    "    'ssd-mobilenet-v1-fpn' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1 FPN SBP\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\",\n",
    "        \"width\" : 640,\n",
    "        \"height\" : 640,\n",
    "    },\n",
    "    'ssd-resnet50-fpn' : {\n",
    "        \"name\" : \"SSD-ResNet50-v1 FPN SBP\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\",\n",
    "        \"width\" : 640,\n",
    "        \"height\" : 640,\n",
    "    },\n",
    "    'ssdlite-mobilenet-v2' : {\n",
    "        \"name\" : \"SSDLite-MobileNet-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "    },\n",
    "    'yolo-v3' : {\n",
    "        \"name\" : \"YOLO-v3\",\n",
    "        \"url\" : \"https://zenodo.org/record/3386327/files/yolo_v3_coco.tar.gz\",\n",
    "        \"width\" : 416,\n",
    "        \"height\" : 416,\n",
    "        \"provenance\" : \"https://github.com/YunYang1994/tensorflow-yolov3/\"\n",
    "    }\n",
    "}\n",
    "    \n",
    "# For each object detection implementation.\n",
    "for implementation in [ 'mlperf-inference-vision' ]:\n",
    "    for benchmark in object_detection_benchmarks.keys():\n",
    "        implementation_benchmark = implementation+'-'+benchmark\n",
    "        implementation_benchmarks[implementation_benchmark] = {\n",
    "            \"input_data_types\": \"fp32\",\n",
    "            \"weight_data_types\": \"fp32\",\n",
    "            \"retraining\": \"no\",\n",
    "            \"starting_weights_filename\": object_detection_benchmarks[benchmark]['url'],\n",
    "#            \"name\" : object_detection_benchmarks[benchmark]['name'], # submission checker complains about \"unknwon field name\"\n",
    "            \"weight_transformations\": \"None (TensorFlow)\"\n",
    "        }\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(implementation_benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implementation_readmes = {}\n",
    "implementation_readmes['image-classification-tflite'] = \\\n",
    "\"\"\"# MLPerf Inference - Image Classification - TFLite\n",
    "\n",
    "This C++ implementation uses TFLite to run TFLite models for Image Classification on CPUs.\n",
    "\n",
    "## Links\n",
    "- [Jupyter notebook](https://nbviewer.jupyter.org/urls/dl.dropbox.com/s/1xlv5oacgobrfd4/mlperf-inference-v0.5-dividiti.ipynb)\n",
    "- [Source code](https://github.com/ctuning/ck-mlperf/tree/master/program/image-classification-tflite-loadgen).\n",
    "- [Instructions](https://github.com/mlperf/inference/blob/master/v0.5/classification_and_detection/optional_harness_ck/classification/tflite/README.md).\n",
    "\"\"\"\n",
    "\n",
    "implementation_readmes['image-classification-armnn-tflite'] = \\\n",
    "\"\"\"# MLPerf Inference - Image Classification - ArmNN-TFLite\n",
    "\n",
    "This C++ implementation uses ArmNN with the TFLite frontend to run TFLite models for Image Classification on Arm Cortex CPUs and Arm Mali GPUs.\n",
    "\n",
    "## Links\n",
    "- [Jupyter notebook](https://nbviewer.jupyter.org/urls/dl.dropbox.com/s/1xlv5oacgobrfd4/mlperf-inference-v0.5-dividiti.ipynb)\n",
    "- [Source code](https://github.com/ctuning/ck-mlperf/tree/master/program/image-classification-armnn-tflite-loadgen).\n",
    "- [Instructions](https://github.com/ARM-software/armnn-mlperf/blob/master/README.md).\n",
    "\"\"\"\n",
    "\n",
    "implementation_readmes['mlperf-inference-vision'] = \\\n",
    "\"\"\"# MLPerf Inference - Object Detection - TensorFlow\n",
    "\n",
    "This Python implementation is the official MLPerf Inference vision application, modified to support other\n",
    "object detection models and run with TensorRT.\n",
    "\n",
    "## Links\n",
    "- [CK wrapper](https://github.com/ctuning/ck-object-detection/tree/master/program/mlperf-inference-vision).\n",
    "- [vision_with_ck branch in dividiti's fork of mlperf/inference](https://github.com/dividiti/inference/tree/vision_with_ck).\n",
    "- [Docker image with instructions](https://github.com/ctuning/ck-mlperf/tree/master/docker/mlperf-inference-vision-with-ck.tensorrt.ubuntu-18.04).\n",
    "- [Jupyter notebook](https://nbviewer.jupyter.org/urls/dl.dropbox.com/s/1xlv5oacgobrfd4/mlperf-inference-v0.5-dividiti.ipynb)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implementation_paths = {}\n",
    "for implementation in [ 'image-classification-tflite', 'image-classification-armnn-tflite', 'mlperf-inference-vision' ]:\n",
    "    implementation_uoa = implementation\n",
    "    if implementation.startswith('image-classification'):\n",
    "        implementation_uoa += '-loadgen'\n",
    "        repo_uoa = 'ck-mlperf'\n",
    "    else: # TODO: move to ck-mlperf, then no need for special case.\n",
    "        repo_uoa = 'ck-object-detection'\n",
    "    r = ck.access({'action':'find', 'repo_uoa':repo_uoa, 'module_uoa':'program', 'data_uoa':implementation_uoa})\n",
    "    if r['return']>0:\n",
    "        print('Error: %s' % r['error'])\n",
    "        exit(1)\n",
    "    implementation_paths[implementation] = r['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_readmes = {}\n",
    "task = 'image-classification'\n",
    "for division_upper in [ 'Closed', 'Open' ]:\n",
    "    division_lower = division_upper.lower()\n",
    "    measurements_readmes[division_lower+'-'+task] = '''# MLPerf Inference - {} Division - Image Classification\n",
    "\n",
    "We performed our measurements using automated, customizable, portable and reproducible\n",
    "[Collective Knowledge](http://cknowledge.org) workflows. Our workflows automatically\n",
    "install dependencies (models, datasets, etc.), preprocess input data in the correct way,\n",
    "and so on.\n",
    "\n",
    "## CK repositories\n",
    "\n",
    "As CK is always evolving, it is hard to pin particular revisions of all repositories.\n",
    "\n",
    "The most relevant repositories and their latest revisions on the submission date (11/Oct/2019):\n",
    "- [ck-mlperf](https://github.com/ctuning/ck-mlperf) @ [ee77cfd](https://github.com/ctuning/ck-mlperf/commit/ee77cfd3ddfa30739a8c2f483fe9ba83a233a000) (contains programs integrated with LoadGen, model packages and scripts).\n",
    "- [ck-env](https://github.com/ctuning/ck-env) @ [f9ac337](https://github.com/ctuning/ck-env/commit/f9ac3372cdc82fa46b2839e45fc67848ab4bac03) (contains dataset descriptions, preprocessing methods, etc.)\n",
    "- [ck-tensorflow](https://github.com/ctuning/ck-tensorflow) @ [eff8bec](https://github.com/ctuning/ck-tensorflow/commit/eff8bec192021162e4a336dbd3e795afa30b7d26) (contains TFLite packages).\n",
    "- [armnn-mlperf](https://github.com/arm-software/armnn-mlperf) @ [42f44a2](https://github.com/ARM-software/armnn-mlperf/commit/42f44a266b6b4e04901255f46f6d34d12589208f) (contains ArmNN/ArmCL packages).\n",
    "\n",
    "## Links\n",
    "- [Bash script](https://github.com/ctuning/ck-mlperf/tree/master/script/mlperf-inference-v0.5.{}.image-classification) used to invoke benchmarking on Linux systems or Android devices.\n",
    "'''.format(division_upper, division_lower)\n",
    "\n",
    "    \n",
    "task = 'object-detection'\n",
    "for division_upper in [ 'Closed', 'Open' ]:\n",
    "    division_lower = division_upper.lower()\n",
    "    measurements_readmes[division_lower+'-'+task] = '''# MLPerf Inference - {} Division - Object Detection\n",
    "\n",
    "We performed our measurements using automated, customizable, portable and reproducible\n",
    "[Collective Knowledge](http://cknowledge.org) workflows. Our workflows automatically\n",
    "install dependencies (models, datasets, etc.), preprocess input data in the correct way,\n",
    "and so on.\n",
    "\n",
    "## CK repositories\n",
    "\n",
    "As CK is always evolving, it is hard to pin particular revisions of all repositories.\n",
    "\n",
    "The most relevant repositories and their latest revisions on the submission date (18/Oct/2019):\n",
    "\n",
    "- [ck-mlperf](https://github.com/ctuning/ck-mlperf) @ [ef1fced](https://github.com/ctuning/ck-mlperf/commit/ef1fcedd495fd03b5ad6d62d62c8ba271854f2ad) (contains the CK program wrapper, MLPerf SSD-MobileNet model packages and scripts).\n",
    "- [ck-object-detection](https://github.com/ctuning/ck-object-detection) @ [780d328](https://github.com/ctuning/ck-object-detection/commit/780d3288ec19656cb60c5ad39b2486bbf0fbf97a) (contains most model packages)\n",
    "- [ck-env](https://github.com/ctuning/ck-env) @ [5af9fbd](https://github.com/ctuning/ck-env/commit/5af9fbd93ad6c6465b631716645ad9442a333442) (contains dataset descriptions, preprocessing methods, etc.)\n",
    "\n",
    "## Links\n",
    "- [Docker image with instructions](https://github.com/ctuning/ck-mlperf/tree/master/docker/mlperf-inference-vision-with-ck.tensorrt.ubuntu-18.04).\n",
    "- [Bash script](https://github.com/ctuning/ck-mlperf/tree/master/script/mlperf-inference-v0.5.{}.object-detection) used to invoke benchmarking via the Docker image.\n",
    "'''.format(division_upper, division_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot of https://github.com/dividiti/inference/blob/61220457dec221ed1984c62bd9d382698bd71bc6/v0.5/mlperf.conf\n",
    "mlperf_conf_6122045 = '''\n",
    "# The format of this config file is 'key = value'.\n",
    "# The key has the format 'model.scenario.key'. Value is mostly int64_t.\n",
    "# Model maybe '*' as wildcard. In that case the value applies to all models.\n",
    "# All times are in milli seconds\n",
    "\n",
    "*.SingleStream.target_latency = 10\n",
    "*.SingleStream.target_latency_percentile = 90\n",
    "*.SingleStream.min_duration = 60000\n",
    "*.SingleStream.min_query_count = 1024\n",
    "\n",
    "*.MultiStream.target_qps = 20\n",
    "*.MultiStream.target_latency_percentile = 99\n",
    "*.MultiStream.samples_per_query = 4\n",
    "*.MultiStream.max_async_queries = 1\n",
    "*.MultiStream.target_latency = 50\n",
    "*.MultiStream.min_duration = 60000\n",
    "*.MultiStream.min_query_count = 270336\n",
    "ssd-resnet34.MultiStream.target_qps = 15\n",
    "ssd-resnet34.MultiStream.target_latency = 66\n",
    "gnmt.MultiStream.min_query_count = 90112\n",
    "gnmt.MultiStream.target_latency = 100\n",
    "gnmt.MultiStream.target_qps = 10\n",
    "gnmt.MultiStream.target_latency_percentile = 97\n",
    "\n",
    "*.Server.target_qps = 1.0\n",
    "*.Server.target_latency = 10\n",
    "*.Server.target_latency_percentile = 99\n",
    "*.Server.target_duration = 0\n",
    "*.Server.min_duration = 60000\n",
    "*.Server.min_query_count = 270336\n",
    "resnet50.Server.target_latency = 15\n",
    "ssd-resnet34.Server.target_latency = 100\n",
    "gnmt.Server.min_query_count = 90112\n",
    "gnmt.Server.target_latency = 250\n",
    "gnmt.Server.target_latency_percentile = 97\n",
    "\n",
    "*.Offline.target_qps = 1.0\n",
    "*.Offline.target_latency_percentile = 90\n",
    "*.Offline.min_duration = 60000\n",
    "*.Offline.min_query_count = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get\"></a>\n",
    "## Get the experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download experimental data and add CK repositories as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_image_classification_closed\"></a>\n",
    "### Image Classification - Closed (MobileNet, ResNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `firefly`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/3md826fk7k1taf3/mlperf.closed.image-classification.firefly.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.firefly.tflite-v1.15.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/jusoz329mhixpxm/mlperf.closed.image-classification.firefly.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.firefly.armnn-v19.08.neon.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/08lzbz7jl2w5jhu/mlperf.closed.image-classification.firefly.armnn-v19.08.opencl.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.firefly.armnn-v19.08.opencl.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `hikey960`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/lqnffl6wbaeceul/mlperf.closed.image-classification.hikey960.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.hikey960.tflite-v1.15.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/6m6uv1d33yc82f8/mlperf.closed.image-classification.hikey960.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.hikey960.armnn-v19.08.neon.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/bz56y4damfqggr8/mlperf.closed.image-classification.hikey960.armnn-v19.08.opencl.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.hikey960.armnn-v19.08.opencl.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `rpi4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/ig97x9cqoxfs3ne/mlperf.closed.image-classification.rpi4.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.rpi4.tflite-v1.15.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/ohcuyes409h66tx/mlperf.closed.image-classification.rpi4.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.rpi4.armnn-v19.08.neon.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `mate10pro`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/r7hss1sd0268b9j/mlperf.closed.image-classification.mate10pro.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.mate10pro.armnn-v19.08.neon.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/iflzxbxcv3qka9x/mlperf.closed.image-classification.mate10pro.armnn-v19.08.opencl.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.mate10pro.armnn-v19.08.opencl.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** We aborted the ResNet accuracy experiment with TFLite, as it was estimated to take 17 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `mate10pro` (only for testing the checker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BAD_LOADGEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/nts8e7unb7vm68f/mlperf.closed.image-classification.mate10pro.tflite-v1.13.mobilenet.BAD_LOADGEN.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.mate10pro.tflite-v1.13.mobilenet.BAD_LOADGEN.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BAD_RESNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/bi2owxxpcfm6n2s/mlperf.closed.image-classification.mate10pro.armnn-v19.08.opencl.BAD_RESNET.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.mate10pro.armnn-v19.08.opencl.BAD_RESNET.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/t2o2elqdyitqlpi/mlperf.closed.image-classification.mate10pro.armnn-v19.08.neon.BAD_RESNET.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.mate10pro.armnn-v19.08.neon.BAD_RESNET.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_image_classification_open\"></a>\n",
    "### Image Classification - Open (MobileNets-v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `firefly`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/q8ieqgnr3zn6w4y/mlperf.open.image-classification.firefly.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.firefly.tflite-v1.15.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/zpenduz1i4qt651/mlperf.open.image-classification.firefly.tflite-v1.15.mobilenet-v1-quantized.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.firefly.tflite-v1.15.mobilenet-v1-quantized.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/3mmefvxc15m9o5b/mlperf.open.image-classification.firefly.armnn-v19.08.opencl.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.firefly.armnn-v19.08.opencl.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/hrupp4o4apo3dfa/mlperf.open.image-classification.firefly.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.firefly.armnn-v19.08.neon.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `hikey960`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/2gbbpsd2pjurvc8/mlperf.open.image-classification.hikey960.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.hikey960.tflite-v1.15.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/rmttjnxzih9snzh/mlperf.open.image-classification.hikey960.tflite-v1.15.mobilenet-v1-quantized.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.hikey960.tflite-v1.15.mobilenet-v1-quantized.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/m5illg8i2tse5hg/mlperf.open.image-classification.hikey960.armnn-v19.08.opencl.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.hikey960.armnn-v19.08.opencl.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/3cujqfe4ps0g66h/mlperf.open.image-classification.hikey960.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.hikey960.armnn-v19.08.neon.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `rpi4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/awhdqjq3p4tre2q/mlperf.open.image-classification.rpi4.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.rpi4.tflite-v1.15.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/rf8vsg5firhjzf8/mlperf.open.image-classification.rpi4.tflite-v1.15.mobilenet-v1-quantized.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.rpi4.tflite-v1.15.mobilenet-v1-quantized.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/0oketvqml7gyzl0/mlperf.open.image-classification.rpi4.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.rpi4.armnn-v19.08.neon.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `mate10pro`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/avi6h9m2demz5zr/mlperf.open.image-classification.mate10pro.tflite-v1.13.mobilenet.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.mate10pro.tflite-v1.13.mobilenet.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/soaw27zcjb8hhww/mlperf.open.image-classification.mate10pro.tflite-v1.13.mobilenet-v1-quantized.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.mate10pro.tflite-v1.13.mobilenet-v1-quantized.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** `mate10pro.tflite-v1.13.mobilenet` would have been a perfectly valid closed submission, just finished a little bit late after the deadline. `mate10pro.tflite-v1.13.mobilenet-quantized` is an open submission alright, as dividiti hadn't declared submitting quantized results before the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_object_detection_open\"></a>\n",
    "### Object Detection - Open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `velociti`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/wiea3a8zf077jsv/mlperf.open.object-detection.velociti.zip\n",
    "$ ck add repo --zip=mlperf.open.object-detection.velociti.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"checklist\"></a>\n",
    "## Generate the submission checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_template = \"\"\"MLPerf Inference 0.5 Self-Certification Checklist\n",
    "\n",
    "Name of Certifying Engineer(s): %(name)s\n",
    "\n",
    "Email of Certifying Engineer(s): %(email)s\n",
    "\n",
    "Name of System(s) Under Test: %(system_name)s\n",
    "\n",
    "Division (check one):\n",
    "- [%(open)s] Open\n",
    "- [%(closed)s] Closed\n",
    "\n",
    "Category (check one):\n",
    "- [%(category_available)s] Available\n",
    "- [%(category_preview)s] Preview\n",
    "- [%(category_rdi)s] Research, Development, and Internal (RDI)\n",
    "\n",
    "Benchmark (check one):\n",
    "- [%(benchmark_mobilenet)s] MobileNet\n",
    "- [ ] SSD-MobileNet\n",
    "- [%(benchmark_resnet)s] ResNet\n",
    "- [ ] SSD-1200\n",
    "- [ ] NMT\n",
    "- [%(benchmark_other)s] Other, please specify: %(benchmark_other_specify)s\n",
    "\n",
    "Please fill in the following tables adding lines as necessary:\n",
    "97%%-tile latency is required for NMT only. 99%%-tile is required for all other models.\n",
    "\n",
    "### Single Stream Results Table\n",
    "| SUT Name | Benchmark | Query Count | Accuracy |\n",
    "|----------|-----------|-------------|----------|\n",
    "| %(system)s | %(benchmark)s | %(query_count)s | %(accuracy_pc)s%% |\n",
    "\n",
    "### Multi-Stream Results Table\n",
    "| SUT Name | Benchmark | Query Count |  Accuracy | 97%%-tile Latency | 99%%-tile Latency |\n",
    "|----------|-----------|-------------|-----------|------------------|------------------|\n",
    "|          |           |             |           |                  |                  |\n",
    "\n",
    "### Server Results Table\n",
    "| SUT Name | Benchmark | Query Count | Accuracy | 97%%-tile Latency | 99%%-tile Latency |\n",
    "|----------|-----------|-------------|----------|------------------|------------------|\n",
    "|          |           |             |          |                  |                  |\n",
    "\n",
    "### Offline Results Table\n",
    "| SUT Name | Benchmark | Sample Count | Accuracy | \n",
    "|----------|-----------|--------------|----------|\n",
    "|          |           |              |          |\n",
    "\n",
    "Scenario (check all that apply):\n",
    "- [%(scenario_singlestream)s] Single-Stream\n",
    "- [%(scenario_multistream)s] Multi-Stream\n",
    "- [%(scenario_server)s] Server\n",
    "- [%(scenario_offline)s] Offline\n",
    "\n",
    "For each SUT, does the submission meet the latency target for each\n",
    "combination of benchmark and scenario? (check all that apply)\n",
    "- [x] Yes (Single-Stream and Offline no requirements)\n",
    "- [ ] Yes (MobileNet x Multi-Stream 50 ms @ 99%%)\n",
    "- [ ] Yes (MobileNet x Server 10 ms @ 99%%)\n",
    "- [ ] Yes (SSD-MobileNet x Multi-Stream 50 ms @ 99%%)\n",
    "- [ ] Yes (SSD-MobileNet x Server 10 ms @ 99%%)\n",
    "- [ ] Yes (ResNet x Multi-Stream 50 ms @ 99%%)\n",
    "- [ ] Yes (ResNet x Server 15 ms @ 99%%)\n",
    "- [ ] Yes (SSD-1200 x Multi-Stream 66 ms @ 99%%).\n",
    "- [ ] Yes (SSD-1200 x Server 100 ms @ 99%%)\n",
    "- [ ] Yes (NMT x Multi-Stream 100 ms @ 97%%)\n",
    "- [ ] Yes (NMT x Server 250 ms @ 97%%)\n",
    "- [ ] No\n",
    "\n",
    "\n",
    "For each SUT, is the appropriate minimum number of queries or samples\n",
    "met, depending on the Scenario x Benchmark? (check all that apply)\n",
    "- [x] Yes (Single-Stream 1,024 queries)\n",
    "- [ ] Yes (Offline 24,576 samples)\n",
    "- [ ] Yes (NMT Server and Multi-Stream 90,112 queries)\n",
    "- [ ] Yes (Image Models Server and Multi-Stream 270,336 queries)\n",
    "- [ ] No\n",
    "\n",
    "For each SUT and scenario, is the benchmark accuracy target met?\n",
    "(check all that apply)\n",
    "- [%(mobilenet_accuracy_met)s] Yes (MobileNet 71.68%% x 98%%)\n",
    "- [ ] Yes (SSD-MobileNet 0.22 mAP x 99%%)\n",
    "- [%(resnet_accuracy_met)s] Yes (ResNet 76.46%% x 99%%)\n",
    "- [ ] Yes (SSD-1200 0.20 mAP x 99%%)\n",
    "- [ ] Yes (NMT 23.9 BLEU x 99%%)\n",
    "- [%(accuracy_not_met)s] No\n",
    "\n",
    "For each SUT and scenario, did the submission run on the whole\n",
    "validation set in accuracy mode? (check one)\n",
    "- [x] Yes\n",
    "- [ ] No\n",
    "\n",
    "How many samples are loaded into the QSL in performance mode?\n",
    "%(performance_sample_count)s\n",
    "\n",
    "For each SUT and scenario, does the number of loaded samples in the\n",
    "QSL in performance mode meet the minimum requirement?  (check all that\n",
    "apply)\n",
    "- [%(performance_sample_count_1024)s] Yes (ResNet and MobileNet 1,024 samples)\n",
    "- [%(performance_sample_count_256)s] Yes (SSD-MobileNet 256 samples)\n",
    "- [%(performance_sample_count_64)s] Yes (SSD-1200 64 samples)\n",
    "- [ ] Yes (NMT 3,903,900 samples)\n",
    "- [%(performance_sample_count_not_met)s] No\n",
    "\n",
    "For each SUT and scenario, is the experimental duration greater than\n",
    "or equal to 60 seconds?  (check one)\n",
    "- [x] Yes\n",
    "- [ ] No\n",
    "\n",
    "Does the submission use LoadGen? (check one)\n",
    "- [x] Yes\n",
    "- [ ] No\n",
    "\n",
    "Is your loadgen commit from one of these allowed commit hashes?\n",
    "- [%(revision_61220457de)s] 61220457dec221ed1984c62bd9d382698bd71bc6\n",
    "- [%(revision_5684c11e39)s] 5684c11e3987b614aae830390fa0e92f56b7e800\n",
    "- [%(revision_55c0ea4e77)s] 55c0ea4e772634107f3e67a6d0da61e6a2ca390d\n",
    "- [%(revision_d31c18fbd9)s] d31c18fbd9854a4f1c489ca1bc4cd818e48f2bc5\n",
    "- [%(revision_1d0e06e54a)s] 1d0e06e54a7d763cf228bdfd8b1e987976e4222f\n",
    "- [%(revision_other)s] Other, please specify: %(revision_other_specify)s\n",
    "\n",
    "Do you have any additional change to LoadGen? (check one)\n",
    "- [ ] Yes, please specify:\n",
    "- [x] No\n",
    "\n",
    "Does the submission run the same code in accuracy and performance\n",
    "modes? (check one)\n",
    "- [x] Yes\n",
    "- [ ] No\n",
    "\n",
    "Where is the LoadGen trace stored? (check one)\n",
    "- [x] Host DRAM\n",
    "- [ ] Other, please specify:\n",
    "\n",
    "For the submitted result, what is the QSL random number generator seed?\n",
    "- [x] 0x2b7e151628aed2a6ULL (3133965575612453542)\n",
    "- [ ] Other, please specify:\n",
    "\n",
    "For the submitted results, what is the sample index random number generator seed?\n",
    "- [x] 0x093c467e37db0c7aULL (665484352860916858)\n",
    "- [ ] Other, please specify:\n",
    "\n",
    "For the submitted results, what is the schedule random number generator seed?\n",
    "- [x] 0x3243f6a8885a308dULL (3622009729038561421)\n",
    "- [ ] Other, please specify:\n",
    "\n",
    "For each SUT and scenario, is the submission run the correct number of\n",
    "times for the relevant scenario? (check one)\n",
    "- [x] Yes (Accuracy 1x Performance 1x Single-Stream, Multi-Stream, Offline)\n",
    "- [ ] Yes (Accuracy 1x Performance 5x Server)\n",
    "- [ ] No\n",
    "\n",
    "Are the weights calibrated using data outside of the calibration set?\n",
    "(check one)\n",
    "- [ ] Yes\n",
    "- [x] No\n",
    "\n",
    "What untimed pre-processing does the submission use? (check all that apply)\n",
    "- [x] Resize\n",
    "- [ ] Reorder channels or transpose\n",
    "- [ ] Pad\n",
    "- [x] A single crop\n",
    "- [x] Mean subtraction and normalization\n",
    "- [ ] Convert to whitelisted format\n",
    "- [ ] No pre-processing\n",
    "- [ ] Other, please specify:\n",
    "\n",
    "What numerics does the submission use? (check all that apply)\n",
    "- [ ] INT4\n",
    "- [ ] INT8\n",
    "- [ ] INT16\n",
    "- [%(numerics_uint8)s] UINT8\n",
    "- [ ] UINT16\n",
    "- [ ] FP11\n",
    "- [ ] FP16\n",
    "- [ ] BF16\n",
    "- [%(numerics_fp32)s] FP32\n",
    "- [ ] Other, please specify:\n",
    "\n",
    "Which of the following techniques does the submission use? (check all that apply)\n",
    "- [ ] Wholesale weight replacement\n",
    "- [ ] Weight supplements\n",
    "- [ ] Discarding non-zero weight elements\n",
    "- [ ] Pruning\n",
    "- [ ] Caching queries\n",
    "- [ ] Caching responses\n",
    "- [ ] Caching intermediate computations\n",
    "- [ ] Modifying weights during the timed portion of an inference run\n",
    "- [ ] Weight quantization algorithms that are similar in size to the\n",
    "non-zero weights they produce\n",
    "- [ ] Hard coding the total number of queries\n",
    "- [ ] Techniques that boost performance for fixed length experiments but\n",
    "are inapplicable to long-running services except in the offline\n",
    "scenario\n",
    "- [ ] Using knowledge of the LoadGen implementation to predict upcoming\n",
    "lulls or spikes in the server scenario\n",
    "- [ ] Treating beams in a beam search differently. For example,\n",
    "employing different precision for different beams\n",
    "- [ ] Changing the number of beams per beam search relative to the reference\n",
    "- [ ] Incorporating explicit statistical information about the performance or accuracy sets\n",
    "- [ ] Techniques that take advantage of upsampled images.\n",
    "- [ ] Techniques that only improve performance when there are identical samples in a query.\n",
    "- [x] None of the above\n",
    "\n",
    "Is the submission congruent with all relevant MLPerf rules?\n",
    "- [x] Yes\n",
    "- [ ] No\n",
    "\n",
    "For each SUT, does the submission accurately reflect the real-world\n",
    "performance of the SUT?\n",
    "- [x] Yes\n",
    "- [ ] No\"\"\"\n",
    "\n",
    "def get_checklist(checklist_template=checklist_template, name='Anton Lokhmotov', email='anton@dividiti.com',\n",
    "                  system='rpi4-tflite-v1.15', system_name='Raspberry Pi 4 (rpi4)', revision='61220457de',\n",
    "                  division='closed', category='available', task='image-classification', benchmark='mobilenet', scenario='singlestream',\n",
    "                  performance_sample_count=1024, performance_sample_count_met=True,\n",
    "                  accuracy_pc=12.345, accuracy_met=True, numerics='fp32'):\n",
    "    def tick(var): return \"x\" if var else \" \"\n",
    "    print(\"=\" * 100)\n",
    "    print(system)\n",
    "    print(\"=\" * 100)\n",
    "    revision_other = revision not in [ '61220457de', '5684c11e39', '55c0ea4e77', 'd31c18fbd9', '1d0e06e54a' ]\n",
    "    benchmark_other = benchmark not in [ 'mobilenet', 'resnet']\n",
    "    if benchmark=='mobilenet':\n",
    "        accuracy_met = accuracy_pc >= 71.676*0.98\n",
    "    elif benchmark=='resnet':\n",
    "        accuracy_met = accuracy_pc >= 76.456*0.99\n",
    "    else:\n",
    "        accuracy_met = accuracy_met and accuracy_pc > 0\n",
    "    checklist = checklist_template % {\n",
    "        \"name\" : name,\n",
    "        \"email\" : email,\n",
    "        \"system_name\": system_name,\n",
    "        # Division.\n",
    "        \"closed\" : tick(division=='closed'),\n",
    "        \"open\" : tick(division=='open'),\n",
    "        # Division.\n",
    "        \"category_available\" : tick(category.lower()=='available'),\n",
    "        \"category_preview\" : tick(category.lower()=='preview'),\n",
    "        \"category_rdi\" : tick(category.lower()=='rdi'),\n",
    "        # Benchmark.\n",
    "        \"benchmark_mobilenet\": tick(benchmark=='mobilenet'),\n",
    "        \"benchmark_resnet\": tick(benchmark=='resnet'),\n",
    "        \"benchmark_other\": tick(benchmark_other),\n",
    "        \"benchmark_other_specify\": benchmark if benchmark_other else '',\n",
    "        # Table.\n",
    "        \"system\" : system,\n",
    "        \"benchmark\" : benchmark,\n",
    "        \"query_count\": 50000 if task=='image-classification' else 5000,\n",
    "        \"accuracy_pc\" : \"%.3f\" % accuracy_pc,\n",
    "        # Scenario.\n",
    "        \"scenario_singlestream\": tick(scenario=='singlestream'),\n",
    "        \"scenario_multistream\": tick(scenario=='multistream'),\n",
    "        \"scenario_server\": tick(scenario=='server'),\n",
    "        \"scenario_offline\": tick(scenario=='offline'),\n",
    "        # Accuracy.\n",
    "        \"mobilenet_accuracy_met\" : tick(benchmark=='mobilenet' and accuracy_met),\n",
    "        \"resnet_accuracy_met\" : tick(benchmark=='resnet' and accuracy_met),\n",
    "        \"accuracy_not_met\" : tick(not accuracy_met),\n",
    "        # \"How many samples are loaded into the QSL in performance mode?\"\n",
    "        \"performance_sample_count\": performance_sample_count,\n",
    "        \"performance_sample_count_1024\": tick(performance_sample_count==1024),\n",
    "        \"performance_sample_count_256\": tick(performance_sample_count==256),\n",
    "        \"performance_sample_count_64\": tick(performance_sample_count==64),\n",
    "        \"performance_sample_count_not_met\": tick(not performance_sample_count_met), # TODO\n",
    "        # LoadGen revision.\n",
    "        \"revision_61220457de\": tick(revision=='61220457de'),\n",
    "        \"revision_5684c11e39\": tick(revision=='5684c11e39'),\n",
    "        \"revision_55c0ea4e77\": tick(revision=='55c0ea4e77'),\n",
    "        \"revision_d31c18fbd9\": tick(revision=='d31c18fbd9'),\n",
    "        \"revision_1d0e06e54a\": tick(revision=='1d0e06e54a'),\n",
    "        \"revision_other\":  tick(revision_other), \n",
    "        \"revision_other_specify\": revision if revision_other else '',\n",
    "        # Numerics.\n",
    "        \"numerics_uint8\": tick(numerics=='uint8'),\n",
    "        \"numerics_fp32\": tick(numerics=='fp32'),\n",
    "    }\n",
    "    print(checklist)\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    return checklist\n",
    "\n",
    "# null = get_checklist(system='rpi4-armnn-v19.08-neon', system_name='Raspberry Pi 4 (rpi4)', benchmark='mobilenet', accuracy_pc=70.241, numerics='uint8')\n",
    "# null = get_checklist(system='hikey960-tflite-v1.15', system_name='Linaro HiKey 960 (hikey960)', benchmark='resnet', accuracy_pc=75.692, revision='deadbeef')\n",
    "null = get_checklist(system='velociti-tensorflow-v1.14-cpu', name='Anton Lokhmotov; Emanuele Vitali', email='anton@dividiti.com; emanuele.vitali@polimi.it', system_name='HP Z640 G1X62EA workstation (velociti)', division='open', category='RDI', benchmark='ssd-mobilenet-fpn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"check\"></a>\n",
    "## Check the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Image Classification - Closed (MobileNet, ResNet).\n",
    "#\n",
    "repos_image_classification_closed = [\n",
    "    # firefly\n",
    "    'mlperf.closed.image-classification.firefly.tflite-v1.15', # https://github.com/mlperf/submissions_inference_0_5/pull/18\n",
    "    'mlperf.closed.image-classification.firefly.armnn-v19.08.neon', # https://github.com/mlperf/submissions_inference_0_5/pull/21\n",
    "    'mlperf.closed.image-classification.firefly.armnn-v19.08.opencl', #https://github.com/mlperf/submissions_inference_0_5/pull/22\n",
    "    # hikey960\n",
    "    'mlperf.closed.image-classification.hikey960.tflite-v1.15', # https://github.com/mlperf/submissions_inference_0_5/pull/23\n",
    "    'mlperf.closed.image-classification.hikey960.armnn-v19.08.neon', # https://github.com/mlperf/submissions_inference_0_5/pull/24\n",
    "    'mlperf.closed.image-classification.hikey960.armnn-v19.08.opencl', # https://github.com/mlperf/submissions_inference_0_5/pull/25\n",
    "    # rpi4\n",
    "    'mlperf.closed.image-classification.rpi4.tflite-v1.15', # https://github.com/mlperf/submissions_inference_0_5/pull/26/\n",
    "    'mlperf.closed.image-classification.rpi4.armnn-v19.08.neon', # https://github.com/mlperf/submissions_inference_0_5/pull/30\n",
    "    # mate10pro\n",
    "    'mlperf.closed.image-classification.mate10pro.armnn-v19.08.neon', # https://github.com/mlperf/submissions_inference_0_5/pull/32\n",
    "    'mlperf.closed.image-classification.mate10pro.armnn-v19.08.opencl', # https://github.com/mlperf/submissions_inference_0_5/pull/35\n",
    "]\n",
    "\n",
    "repos_image_classification_closed_audit = [\n",
    "    'mlperf.closed.image-classification.firefly.audit', # https://github.com/mlperf/submissions_inference_0_5/pull/234\n",
    "    'mlperf.closed.image-classification.hikey960.audit', # https://github.com/mlperf/submissions_inference_0_5/pull/236\n",
    "    'mlperf.closed.image-classification.rpi4.audit', # https://github.com/mlperf/submissions_inference_0_5/pull/238\n",
    "    #'mlperf.closed.image-classification.mate10pro.audit',\n",
    "]\n",
    "\n",
    "#\n",
    "# Image Classification - Open (MobileNets-v1,v2).\n",
    "#\n",
    "repos_image_classification_open = [\n",
    "    # firefly\n",
    "    'mlperf.open.image-classification.firefly.tflite-v1.15', # https://github.com/mlperf/submissions_inference_0_5/pull/39\n",
    "    'mlperf.open.image-classification.firefly.tflite-v1.15.mobilenet-v1-quantized', # https://github.com/mlperf/submissions_inference_0_5/pull/127\n",
    "    'mlperf.open.image-classification.firefly.armnn-v19.08.opencl', # https://github.com/mlperf/submissions_inference_0_5/pull/40\n",
    "    'mlperf.open.image-classification.firefly.armnn-v19.08.neon', # https://github.com/mlperf/submissions_inference_0_5/pull/120\n",
    "    # hikey960\n",
    "    'mlperf.open.image-classification.hikey960.tflite-v1.15', # https://github.com/mlperf/submissions_inference_0_5/pull/37\n",
    "    'mlperf.open.image-classification.hikey960.tflite-v1.15.mobilenet-v1-quantized', # https://github.com/mlperf/submissions_inference_0_5/pull/128\n",
    "    'mlperf.open.image-classification.hikey960.armnn-v19.08.opencl', # https://github.com/mlperf/submissions_inference_0_5/pull/38\n",
    "    'mlperf.open.image-classification.hikey960.armnn-v19.08.neon', # https://github.com/mlperf/submissions_inference_0_5/pull/121\n",
    "    # rpi4\n",
    "    'mlperf.open.image-classification.rpi4.tflite-v1.15', # https://github.com/mlperf/submissions_inference_0_5/pull/122\n",
    "    'mlperf.open.image-classification.rpi4.tflite-v1.15.mobilenet-v1-quantized', # https://github.com/mlperf/submissions_inference_0_5/pull/129\n",
    "    'mlperf.open.image-classification.rpi4.armnn-v19.08.neon', # https://github.com/mlperf/submissions_inference_0_5/pull/123\n",
    "    # mate10pro\n",
    "    'mlperf.open.image-classification.mate10pro.tflite-v1.13.mobilenet', # https://github.com/mlperf/submissions_inference_0_5/pull/130\n",
    "    'mlperf.open.image-classification.mate10pro.tflite-v1.13.mobilenet-v1-quantized', # https://github.com/mlperf/submissions_inference_0_5/pull/135\n",
    "]\n",
    "\n",
    "repos_image_classification_open_audit = [\n",
    "    'mlperf.open.image-classification.firefly.audit', # https://github.com/mlperf/submissions_inference_0_5/pull/255\n",
    "    'mlperf.open.image-classification.hikey960.audit', # https://github.com/mlperf/submissions_inference_0_5/pull/257\n",
    "    'mlperf.open.image-classification.rpi4.audit', # https://github.com/mlperf/submissions_inference_0_5/pull/258\n",
    "    #'mlperf.open.image-classification.mate10pro.audit',\n",
    "]\n",
    "\n",
    "#\n",
    "# Object Detection - Open (TensorFlow Model Zoo + YOLO-v3)\n",
    "#\n",
    "repos_object_detection_open = [\n",
    "    # velociti\n",
    "    'mlperf.open.object-detection.velociti', # https://www.dropbox.com/s/wiea3a8zf077jsv/mlperf.open.object-detection.velociti.zip\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repos_for_testing = [\n",
    "#     'mlperf.closed.image-classification.mate10pro.tflite-v1.13.mobilenet.BAD_LOADGEN',\n",
    "#     'mlperf.closed.image-classification.mate10pro.armnn-v19.08.opencl.BAD_RESNET',\n",
    "#     'mlperf.closed.image-classification.mate10pro.armnn-v19.08.neon.BAD_RESNET',\n",
    "#     'mlperf-inference-vision-experiments-count5'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!ck recache repo\n",
    "# for repo_uoa in repos:\n",
    "#     print(\"=\" * 100)\n",
    "#     print(repo_uoa)\n",
    "#     print(\"=\" * 100)\n",
    "#     !ck list $repo_uoa:experiment:* | sort\n",
    "#     print(\"-\" * 100)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate upstream master.\n",
    "# r = ck.access({'action':'locate', 'module_uoa':'env', 'tags':'mlperf,inference,source,upstream.master'})\n",
    "# Locate variation with audit test fixes.\n",
    "r = ck.access({'action':'locate', 'module_uoa':'env', 'tags':'mlperf,inference,source,upstream.pr518'})\n",
    "if r['return']>0:\n",
    "    print('Error: %s' % r['error'])\n",
    "    exit(1)\n",
    "# Pick any source location and look under 'inference/v0.5/mlperf.conf'.\n",
    "upstream_path = os.path.join(list(r['install_locations'].values())[0], 'inference')\n",
    "upstream_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_experimental_results(repo_uoa, module_uoa='experiment', tags='mlperf', submitter='dividiti', path=None, audit=False):\n",
    "    if not path:\n",
    "        path_list = !ck find repo:$repo_uoa\n",
    "        path = path_list[0]\n",
    "    root_dir = os.path.join(path, 'submissions_inference_0_5')\n",
    "    if not os.path.exists(root_dir): os.mkdir(root_dir)\n",
    "    print(\"Storing results under '%s'\" % root_dir)\n",
    "    \n",
    "    r = ck.access({'action':'search', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'tags':tags})\n",
    "    if r['return']>0:\n",
    "        print('Error: %s' % r['error'])\n",
    "        exit(1)\n",
    "    experiments = r['lst']\n",
    "\n",
    "    for experiment in experiments:\n",
    "        data_uoa = experiment['data_uoa']\n",
    "        r = ck.access({'action':'list_points', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'data_uoa':data_uoa})\n",
    "        if r['return']>0:\n",
    "            print('Error: %s' % r['error'])\n",
    "            exit(1)\n",
    "        print(\"*\" * 100)\n",
    "\n",
    "        tags = r['dict']['tags']\n",
    "        #print(tags)\n",
    "        backend = ''\n",
    "        preprocessing = ''\n",
    "        if 'velociti' in tags:\n",
    "            # Expected format: [ \"mlperf\", \"open\", \"object-detection\", \"velociti\", \"cpu\", \"rcnn-inception-resnet-v2-lowproposals\", \"singlestream\", \"accuracy\" ]\n",
    "            (_, division, task, platform, backend, benchmark, scenario, mode) = tags\n",
    "            library = 'tensorflow-v1.14'\n",
    "        elif 'accuracy' in tags:\n",
    "            # FIXME: With the benefit of hindsight, [ ..., \"armnn-v19.08\", \"neon\", ... ] should have come \n",
    "            # as one tag \"armnn-v19.08-neon\", since we join them in this notebook anyway.\n",
    "            if 'neon' in tags or 'opencl' in tags:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"armnn-v19.08\", \"neon\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"accuracy\", \"using-opencv\" ]\n",
    "                (_, division, task, platform, library, backend, benchmark, scenario, mode, preprocessing) = tags\n",
    "            else:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"tflite-v1.15\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"accuracy\", \"using-opencv\" ]\n",
    "                (_, division, task, platform, library, benchmark, scenario, mode, preprocessing) = tags\n",
    "        elif 'performance' in tags:            \n",
    "            if 'neon' in tags or 'opencl' in tags:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"armnn-v19.08\", \"neon\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"performance\" ]\n",
    "                (_, division, task, platform, library, backend, benchmark, scenario, mode) = tags\n",
    "            else:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"tflite-v1.15\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"performance\" ]\n",
    "                (_, division, task, platform, library, benchmark, scenario, mode) = tags\n",
    "        elif 'audit' in tags: # As accuracy but with the test name instead of the preprocessing method.\n",
    "            if 'neon' in tags or 'opencl' in tags:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"armnn-v19.08\", \"neon\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"audit\", \"TEST03\" ]\n",
    "                (_, division, task, platform, library, backend, benchmark, scenario, mode, test) = tags\n",
    "            else:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"tflite-v1.15\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"audit\", \"TEST03\" ]\n",
    "                (_, division, task, platform, library, benchmark, scenario, mode, test) = tags\n",
    "        else:\n",
    "            raise \"Expected 'accuracy' or 'performance' or 'audit' in tags!\"\n",
    "\n",
    "#         if mode == 'accuracy': continue\n",
    "            \n",
    "        organization = submitter\n",
    "\n",
    "        if backend != '':\n",
    "            system = platform+'-'+library+'-'+backend\n",
    "        else:\n",
    "            system = platform+'-'+library\n",
    "        division_system = division+'-'+system\n",
    "\n",
    "        if library.startswith('tflite'):\n",
    "            implementation = task+'-tflite'\n",
    "        elif library.startswith('armnn'):\n",
    "            implementation = task+'-armnn-tflite'\n",
    "        else: # Official app with CK adaptations.\n",
    "            implementation = 'mlperf-inference-vision'\n",
    "        implementation_benchmark = implementation+'-'+benchmark\n",
    "        \n",
    "        #\n",
    "        # Directory structure according to the Inference section of the General MLPerf Submission Rules:\n",
    "        # https://github.com/mlperf/policies/blob/master/submission_rules.adoc#552-inference\n",
    "        #\n",
    "        # <division>/\n",
    "        #   <organization>/\n",
    "        #\n",
    "        division_dir = os.path.join(root_dir, division)\n",
    "        if not os.path.exists(division_dir): os.mkdir(division_dir)\n",
    "        organization_dir = os.path.join(division_dir, organization)\n",
    "        if not os.path.exists(organization_dir): os.mkdir(organization_dir)\n",
    "        \n",
    "        #\n",
    "        #     \"systems\"/\n",
    "        #       <system_desc_id>.json\n",
    "        #\n",
    "        systems_dir = os.path.join(organization_dir, 'systems')\n",
    "        if not os.path.exists(systems_dir): os.mkdir(systems_dir)\n",
    "        system_json_name = '%s.json' % system\n",
    "        system_json_path = os.path.join(systems_dir, system_json_name)\n",
    "        with open(system_json_path, 'w') as system_json_file:\n",
    "#             pprint(division_system)\n",
    "#             pprint(division_systems)\n",
    "            system_json = division_systems.get(division_system, default_system_json)\n",
    "            json.dump(system_json, system_json_file, indent=2)\n",
    "            print('%s' % systems_dir)\n",
    "            if system_json == default_system_json:\n",
    "                print('  |_ %s [DEFAULT]' % system_json_name)\n",
    "                raise\n",
    "            else:\n",
    "                print('  |_ %s [%s]' % (system_json_name, division_system))\n",
    "        \n",
    "        #\n",
    "        #     \"code\"/\n",
    "        #       <benchmark_name_per_reference>/\n",
    "        #         <implementation_id>/\n",
    "        #           <Code interface with loadgen and other arbitrary stuff>\n",
    "        #\n",
    "        code_dir = os.path.join(organization_dir, 'code')\n",
    "        if not os.path.exists(code_dir): os.mkdir(code_dir)\n",
    "        # FIXME: For now, not always \"per reference\".\n",
    "        benchmark_dir = os.path.join(code_dir, benchmark)\n",
    "        if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)            \n",
    "        implementation_dir = os.path.join(benchmark_dir, implementation)\n",
    "        if not os.path.exists(implementation_dir): os.mkdir(implementation_dir)\n",
    "        print('%s' % code_dir)\n",
    "\n",
    "        # Create 'README.md'.\n",
    "        implementation_readme_name = 'README.md'\n",
    "        implementation_readme_path = os.path.join(implementation_dir, implementation_readme_name)\n",
    "#         pprint(implementation)\n",
    "#         pprint(implementation_readmes)\n",
    "        implementation_readme = implementation_readmes.get(implementation, '')\n",
    "        with open(implementation_readme_path, 'w') as implementation_readme_file:\n",
    "            implementation_readme_file.writelines(implementation_readme)\n",
    "        if implementation_readme == '':\n",
    "            print('  |_ %s [EMPTY]' % implementation_readme_name)\n",
    "            raise\n",
    "        else:\n",
    "            print('  |_ %s' % implementation_readme_name)\n",
    "\n",
    "        #\n",
    "        #     \"measurements\"/\n",
    "        #       <system_desc_id>/\n",
    "        #         <benchmark>/\n",
    "        #           <scenario>/\n",
    "        #             <system_desc_id>_<implementation_id>.json\n",
    "        #             README.md\n",
    "        #             user.conf\n",
    "        #             mlperf.conf\n",
    "        #             calibration_process.adoc (?)\n",
    "        #             submission_checklist.txt\n",
    "        #\n",
    "        measurements_dir = os.path.join(organization_dir, 'measurements')\n",
    "        if not os.path.exists(measurements_dir): os.mkdir(measurements_dir)\n",
    "        system_dir = os.path.join(measurements_dir, system)\n",
    "        if not os.path.exists(system_dir): os.mkdir(system_dir)\n",
    "        benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "        if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)\n",
    "        scenario_dir = os.path.join(benchmark_dir, scenario)\n",
    "        if not os.path.exists(scenario_dir): os.mkdir(scenario_dir)\n",
    "        print(scenario_dir)\n",
    "        \n",
    "        # Create '<system_desc_id>_<implementation_id>.json'.\n",
    "        system_implementation_json_name = system+'_'+implementation+'.json'\n",
    "        system_implementation_json_path = os.path.join(scenario_dir, system_implementation_json_name)\n",
    "        with open(system_implementation_json_path, 'w') as system_implementation_json_file:\n",
    "            implementation_benchmark_json = implementation_benchmarks.get(implementation_benchmark, default_implementation_benchmark_json)\n",
    "            if implementation_benchmark_json != default_implementation_benchmark_json:\n",
    "                print('  |_ %s [for %s]' % (system_implementation_json_name, implementation_benchmark))\n",
    "                json.dump(implementation_benchmark_json, system_implementation_json_file, indent=2)\n",
    "            else:\n",
    "                print('  |_ %s [DEFAULT]' % system_implementation_json_name)\n",
    "                raise \"Default implementation!\"\n",
    "        \n",
    "        # Create 'README.md' based on the division and task (basically, mentions a division- and task-specific script).\n",
    "        measurements_readme_name = 'README.md'\n",
    "        measurements_readme_path = os.path.join(scenario_dir, measurements_readme_name)\n",
    "        measurements_readme = measurements_readmes.get(division+'-'+task, '')\n",
    "        if measurements_readme != '':\n",
    "            with open(measurements_readme_path, 'w') as measurements_readme_file:\n",
    "                measurements_readme_file.writelines(measurements_readme)\n",
    "            print('  |_ %s [for %s %s]' % (measurements_readme_name, division, task))\n",
    "        else:\n",
    "            raise \"Invalid measurements README!\"\n",
    "        \n",
    "        # Copy 'user.conf' from implementation source.\n",
    "        user_conf_name = 'user.conf'\n",
    "        implementation_path = implementation_paths.get(implementation, '')\n",
    "#         pprint(implementation)\n",
    "#         pprint(implementation_paths)\n",
    "        if implementation_path != '':\n",
    "            user_conf_path = os.path.join(implementation_path, user_conf_name)\n",
    "            copy2(user_conf_path, scenario_dir)\n",
    "            print('  |_ %s [from %s]' % (user_conf_name, user_conf_path))\n",
    "        else:\n",
    "            raise \"Invalid implementation path!\"\n",
    "        \n",
    "        # Copy 'mlperf.conf' from MLPerf Inference source.\n",
    "        mlperf_conf_name = 'mlperf.conf'\n",
    "        mlperf_conf_path = os.path.join(scenario_dir, mlperf_conf_name)\n",
    "        if implementation in [ 'image-classification-tflite', 'image-classification-armnn-tflite' ]:\n",
    "            # Write a snapshot from https://github.com/dividiti/inference/blob/61220457dec221ed1984c62bd9d382698bd71bc6/v0.5/mlperf.conf\n",
    "            with open(mlperf_conf_path, 'w') as mlperf_conf_file:\n",
    "                mlperf_conf_file.writelines(mlperf_conf_6122045)\n",
    "            print('  |_ %s [from %s]' % (mlperf_conf_name, 'github.com/mlperf/inference@6122045'))\n",
    "        else:\n",
    "            upstream_mlperf_conf_path = os.path.join(upstream_path, 'v0.5', 'mlperf.conf')\n",
    "            copy2(upstream_mlperf_conf_path, mlperf_conf_path)\n",
    "            print('  |_ %s [from %s]' % (mlperf_conf_name, upstream_mlperf_conf_path))\n",
    "\n",
    "        # Write submission_checklist.txt into the same directory later, once accuracy.txt is parsed.\n",
    "        \n",
    "        #\n",
    "        #     \"results\"/\n",
    "        #       <system_desc_id>/\n",
    "        #         <benchmark>/\n",
    "        #           <scenario>/\n",
    "        #             performance/\n",
    "        #               run_x/ # 1 run for single stream and offline, 5 otherwise\n",
    "        #                 mlperf_log_summary.txt\n",
    "        #                 mlperf_log_detail.txt\n",
    "        #                 mlperf_log_trace.json\n",
    "        #             accuracy/\n",
    "        #               mlperf_log_accuracy.json\n",
    "        #         compliance_checker_log.txt\n",
    "        #\n",
    "        results_dir = os.path.join(organization_dir, 'results')\n",
    "        if not os.path.exists(results_dir): os.mkdir(results_dir)\n",
    "        system_dir = os.path.join(results_dir, system)\n",
    "        if not os.path.exists(system_dir): os.mkdir(system_dir)\n",
    "        benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "        if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)\n",
    "        scenario_dir = os.path.join(benchmark_dir, scenario)\n",
    "        if not os.path.exists(scenario_dir): os.mkdir(scenario_dir)\n",
    "        mode_dir = os.path.join(scenario_dir, mode)\n",
    "        if not os.path.exists(mode_dir): os.mkdir(mode_dir)\n",
    "        print(mode_dir)\n",
    "        \n",
    "        if audit:\n",
    "            # Deal with a subset of audit tests.\n",
    "#             if test not in [ 'TEST03' ]: # [ 'TEST01', 'TEST03', 'TEST04-A', 'TEST04-B', 'TEST05' ]:\n",
    "#                 continue\n",
    "            # Save the accuracy and performance dirs for the corresponding submission experiment.\n",
    "            accuracy_dir = os.path.join(scenario_dir, 'accuracy')\n",
    "            performance_dir = os.path.join(scenario_dir, 'performance', 'run_1')\n",
    "            # Use the mode expected for each test.\n",
    "            mode = 'performance' if test != 'TEST03' else 'submission'\n",
    "            # Create a similar directory structure to results_dir, with another level, test_dir,\n",
    "            # between scenario_dir and mode_dir.\n",
    "            audit_dir = os.path.join(organization_dir, 'audit')\n",
    "            if not os.path.exists(audit_dir): os.mkdir(audit_dir)\n",
    "            system_dir = os.path.join(audit_dir, system)\n",
    "            if not os.path.exists(system_dir): os.mkdir(system_dir)\n",
    "            benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "            if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)\n",
    "            scenario_dir = os.path.join(benchmark_dir, scenario)\n",
    "            if not os.path.exists(scenario_dir): os.mkdir(scenario_dir)\n",
    "            test_dir = os.path.join(scenario_dir, test)\n",
    "            if not os.path.exists(test_dir): os.mkdir(test_dir)\n",
    "            mode_dir = os.path.join(test_dir, mode)\n",
    "            if not os.path.exists(mode_dir): os.mkdir(mode_dir)\n",
    "\n",
    "        # For each point (should be one point for each performance run).\n",
    "        points = r['points']\n",
    "        for (point, point_idx) in zip(points, range(1,len(points)+1)):\n",
    "            point_file_path = os.path.join(r['path'], 'ckp-%s.0001.json' % point)\n",
    "            with open(point_file_path) as point_file:\n",
    "                point_data_raw = json.load(point_file)\n",
    "            characteristics_list = point_data_raw['characteristics_list']\n",
    "            characteristics = characteristics_list[0]\n",
    "\n",
    "            # Set the leaf directory.\n",
    "            if mode == 'performance':\n",
    "                run_dir = os.path.join(mode_dir, 'run_%d' % point_idx)\n",
    "                if not os.path.exists(run_dir): os.mkdir(run_dir)\n",
    "                last_dir = run_dir\n",
    "            else:\n",
    "                last_dir = mode_dir\n",
    "            print(last_dir)\n",
    "\n",
    "            # Dump files in the leaf directory.\n",
    "            mlperf_log = characteristics['run'].get('mlperf_log',{})\n",
    "            # Summary file (with errors and warnings in accuracy mode, with statistics in performance mode).\n",
    "            summary_txt_name = 'mlperf_log_summary.txt'\n",
    "            summary_txt_path = os.path.join(last_dir, summary_txt_name)\n",
    "            summary = mlperf_log.get('summary','')\n",
    "            with open(summary_txt_path, 'w') as summary_txt_file:\n",
    "                summary_txt_file.writelines(summary)\n",
    "                print('  |_ %s' % summary_txt_name)\n",
    "            # Detail file (with settings).\n",
    "            detail_txt_name = 'mlperf_log_detail.txt'\n",
    "            detail_txt_path = os.path.join(last_dir, detail_txt_name)\n",
    "            detail = mlperf_log.get('detail','')\n",
    "            with open(detail_txt_path, 'w') as detail_txt_file:\n",
    "                detail_txt_file.writelines(detail)\n",
    "                print('  |_ %s' % detail_txt_name)\n",
    "            # Accuracy file (with accuracy dictionary).\n",
    "            # TODO: Move the next 5 lines into the (if mode == 'accuracy') block,\n",
    "            # once the submission checker no longer complains as follows:\n",
    "            # \"performance/run_1 has file list mismatch (['mlperf_log_accuracy.json'])\"\n",
    "            accuracy_json_name = 'mlperf_log_accuracy.json'\n",
    "            accuracy_json_path = os.path.join(last_dir, accuracy_json_name)\n",
    "            with open(accuracy_json_path, 'w') as accuracy_json_file:\n",
    "                json.dump(mlperf_log.get('accuracy',{}), accuracy_json_file, indent=2)\n",
    "                print('  |_ %s' % accuracy_json_name)\n",
    "            # Do what's required by NVIDIA's audit tests.\n",
    "            if audit:\n",
    "                test_path = os.path.join(upstream_path, 'v0.5', 'audit', 'nvidia', test)\n",
    "                if 'TEST01' in tags:\n",
    "                    # Verify that the accuracy (partially) dumped for the audit test matches that for the submision.\n",
    "                    verify_accuracy_py = os.path.join(test_path, 'verify_accuracy.py')\n",
    "                    submission_accuracy_json_path = os.path.join(accuracy_dir, accuracy_json_name)\n",
    "                    verify_accuracy_txt = !python3 $verify_accuracy_py -a $submission_accuracy_json_path -p $accuracy_json_path\n",
    "                    verify_accuracy_txt_name = 'verify_accuracy.txt'\n",
    "                    verify_accuracy_txt_path = os.path.join(test_dir, verify_accuracy_txt_name)\n",
    "                    with open(verify_accuracy_txt_path, 'w') as verify_accuracy_txt_file:\n",
    "                        verify_accuracy_txt_file.writelines('\\n'.join(verify_accuracy_txt))\n",
    "                        print('%s' % test_dir)\n",
    "                        print('  |_ %s' % verify_accuracy_txt_name)\n",
    "                if test in [ 'TEST01', 'TEST03', 'TEST05' ]:\n",
    "                    # Verify that the performance for the audit test matches that for the submission.\n",
    "                    verify_performance_py = os.path.join(test_path, 'verify_performance.py')\n",
    "                    submission_summary_txt_path = os.path.join(performance_dir, summary_txt_name)\n",
    "                    verify_performance_txt = !python3 $verify_performance_py -r $submission_summary_txt_path -t $summary_txt_path\n",
    "                    verify_performance_txt_name = 'verify_performance.txt'\n",
    "                    verify_performance_txt_path = os.path.join(test_dir, verify_performance_txt_name)\n",
    "                    with open(verify_performance_txt_path, 'w') as verify_performance_txt_file:\n",
    "                        verify_performance_txt_file.writelines('\\n'.join(verify_performance_txt))\n",
    "                        print('%s' % test_dir)\n",
    "                        print('  |_ %s' % verify_performance_txt_name)\n",
    "                if test in [ 'TEST04-A', 'TEST04-B' ]:\n",
    "                    test04a_summary_txt_path = os.path.join(scenario_dir, 'TEST04-A', 'performance', 'run_1', summary_txt_name)\n",
    "                    test04b_summary_txt_path = os.path.join(scenario_dir, 'TEST04-B', 'performance', 'run_1', summary_txt_name)\n",
    "                    if os.path.exists(test04a_summary_txt_path) and os.path.exists(test04b_summary_txt_path):\n",
    "                        # If both tests have been processed, verify that their performance matches.\n",
    "                        verify_performance_py = os.path.join(upstream_path, 'v0.5', 'audit', 'nvidia', 'TEST04-A', 'verify_test4_performance.py')\n",
    "                        #print(\"python3 {} -u {} -s {}\".format(verify_performance_py, test04a_summary_txt_path, test04b_summary_txt_path))\n",
    "                        verify_performance_txt = !python3 $verify_performance_py -u $test04a_summary_txt_path -s $test04b_summary_txt_path\n",
    "                        #print(verify_performance_txt)\n",
    "                        verify_performance_txt_name = 'verify_performance.txt'\n",
    "                        verify_performance_txt_path = os.path.join(scenario_dir, 'TEST04-A', verify_performance_txt_name)\n",
    "                        with open(verify_performance_txt_path, 'w') as verify_performance_txt_file:\n",
    "                            verify_performance_txt_file.writelines('\\n'.join(verify_performance_txt))\n",
    "                            print('%s' % os.path.join(scenario_dir, 'TEST04-A'))\n",
    "                            print('  |_ %s' % verify_performance_txt_name)\n",
    "                    else:\n",
    "                        # Need both A/B tests to be processed. Wait for the other one.\n",
    "                        continue\n",
    "            # Generate accuracy.txt.\n",
    "            if mode == 'accuracy' or mode == 'submission':\n",
    "                accuracy_txt_name = 'accuracy.txt'\n",
    "                accuracy_txt_path = os.path.join(last_dir, accuracy_txt_name)\n",
    "                if task == 'image-classification':\n",
    "                    accuracy_imagenet_py = os.path.join(upstream_path, 'v0.5', 'classification_and_detection', 'tools', 'accuracy-imagenet.py')\n",
    "                    imagenet_val_file = '$HOME/CK_TOOLS/dataset-imagenet-ilsvrc2012-aux/val.txt' # FIXME: Do not hardcode - locate via CK.\n",
    "                    accuracy_txt = !python3 $accuracy_imagenet_py --imagenet-val-file $imagenet_val_file --mlperf-accuracy-file $accuracy_json_path\n",
    "                    # The last (and only line) is e.g. \"accuracy=76.442%, good=38221, total=50000\".\n",
    "                    accuracy_line = accuracy_txt[-1]\n",
    "                    match = re.match('accuracy=(.+)%, good=(\\d+), total=(\\d+)', accuracy_line)\n",
    "                    accuracy_pc = float(match.group(1))\n",
    "                elif task == 'object-detection':\n",
    "                    accuracy_coco_py = os.path.join(upstream_path, 'v0.5', 'classification_and_detection', 'tools', 'accuracy-coco.py')\n",
    "                    coco_dir = '/home/anton/CK_TOOLS/dataset-coco-2017-val' # FIXME: Do not hardcode - locate via CK.\n",
    "                    os.environ['PYTHONPATH'] = pythonpath_coco+':'+os.environ.get('PYTHONPATH','')\n",
    "                    accuracy_txt = !python3 $accuracy_coco_py --coco-dir $coco_dir --mlperf-accuracy-file $accuracy_json_path\n",
    "                    # The last line is e.g. \"mAP=13.323%\".\n",
    "                    accuracy_line = accuracy_txt[-1]\n",
    "                    match = re.match('mAP\\=([\\d\\.]+)\\%', accuracy_line)\n",
    "                    accuracy_pc = float(match.group(1))\n",
    "                else:\n",
    "                    raise \"Invalid task '%s'!\" % task\n",
    "                with open(accuracy_txt_path, 'w') as accuracy_txt_file:\n",
    "                    accuracy_txt_file.writelines('\\n'.join(accuracy_txt))\n",
    "                    print('  |_ %s [%.3f%% parsed from \"%s\"]' % (accuracy_txt_name, accuracy_pc, accuracy_line))\n",
    "            # Generate submission_checklist.txt for each system, benchmark and scenario under \"measurements/\".\n",
    "            if mode == 'accuracy' and not audit:\n",
    "                checklist_name = 'submission_checklist.txt'\n",
    "                checklist_path = os.path.join(measurements_dir, system, benchmark, scenario, checklist_name)\n",
    "                system_json = division_systems.get(division_system, default_system_json)\n",
    "\n",
    "                # Extract LoadGen revision from the second line of e.g.\n",
    "                # \"pid\": 28660, \"tid\": 28660, \"ts\": 8750ns : version : .5a1 @ 61220457de\n",
    "                # FIXME: In practice, the revision may be different for accuracy and performance runs\n",
    "                # (happened on rpi4 due to a late LoadGen fix). We would prefer to use one from \n",
    "                # the performance one, as it may be more critical for performance evaluation.\n",
    "                # However, as we only write the checklist from the accuracy run, we are somewhat stuck.\n",
    "                loadgen_revision = detail[1].split('@')[1].strip()\n",
    "                \n",
    "                # FIXME: The actual performance_sample_count can be extracted from the performance run.\n",
    "                # Again, this is not available to us here.\n",
    "                # We could check in user.conf, but we would need to parse it.\n",
    "                performance_sample_count = 1024 if task == 'image-classification' else 256\n",
    "                # Write the checklist.\n",
    "                if division == 'open' and task == 'object-detection':\n",
    "                    # Collaboration between dividiti and Politecnico di Milano.\n",
    "                    print(system)\n",
    "                    checklist = get_checklist(name='Anton Lokhmotov; Emanuele Vitali',\n",
    "                                              email='anton@dividiti.com; emanuele.vitali@polimi.it',\n",
    "                                              division=division, task=task, system=system,\n",
    "                                              system_name=system_json['system_name'], category=system_json['status'],\n",
    "                                              revision=loadgen_revision, benchmark=benchmark, accuracy_pc=accuracy_pc,\n",
    "                                              performance_sample_count=performance_sample_count,\n",
    "                                              numerics=implementation_benchmark_json['weight_data_types'])\n",
    "                else:\n",
    "                    checklist = get_checklist(division=division, task=task, system=system,\n",
    "                                              system_name=system_json['system_name'], category=system_json['status'],\n",
    "                                              revision=loadgen_revision, benchmark=benchmark, accuracy_pc=accuracy_pc,\n",
    "                                              performance_sample_count=performance_sample_count,\n",
    "                                              numerics=implementation_benchmark_json['weight_data_types'])\n",
    "                with open(checklist_path, 'w') as checklist_file:\n",
    "                    checklist_file.writelines(checklist)\n",
    "\n",
    "#             # Trace file (should omit trace from v0.5).\n",
    "#             trace_json_name = 'mlperf_log_trace.json'\n",
    "#             trace_json_path = os.path.join(last_dir, trace_json_name)\n",
    "#             with open(trace_json_path, 'w') as trace_json_file:\n",
    "#                 json.dump(mlperf_log.get('trace',{}), trace_json_file, indent=2)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path is where mlperf/submissions_inference_0_5 is cloned under.\n",
    "path = '/home/anton/projects/mlperf/'\n",
    "submitter = 'dividiti'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract submission repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # repos = repos_image_classification_closed + repos_image_classification_open + repos_object_detection_open\n",
    "# repos = [ 'mlperf.open.image-classification.firefly.tflite-v1.15.mobilenet-v1-quantized' ]\n",
    "# for repo_uoa in repos:\n",
    "#     check_experimental_results(repo_uoa, path=path, submitter=submitter, audit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract audit repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # audit_repos = repos_image_classification_closed_audit + repos_image_classification_open_audit\n",
    "# audit_repos = [ 'mlperf.closed.image-classification.mate10pro.audit' ]\n",
    "# for repo_uoa in audit_repos:\n",
    "#     check_experimental_results(repo_uoa, path=path, submitter=submitter, audit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run submission checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"*\" * 100)\n",
    "submission_checker_py = os.path.join(upstream_path, 'v0.5', 'tools', 'submission', 'submission-checker.py')\n",
    "# The checker has a weird bug. When submitting to open, 'closed/<organization>/results' must exist on disk.\n",
    "# Vice versa, When submitting to closed, 'open/<organization>/results' must exist on disk. \n",
    "# Therefore, create both directories if they do not exist before invoking the checker.\n",
    "root_dir = os.path.join(path, 'submissions_inference_0_5')\n",
    "open_org_results_dir = os.path.join(root_dir, 'open', submitter, 'results')\n",
    "closed_org_results_dir = os.path.join(root_dir, 'closed', submitter, 'results')\n",
    "!mkdir -p $open_org_results_dir\n",
    "!mkdir -p $closed_org_results_dir\n",
    "# Run the checker.\n",
    "checker_log = !python3 $submission_checker_py --input $root_dir --submitter $submitter\n",
    "checker_log = \"\\n\".join(checker_log)\n",
    "print(checker_log)\n",
    "checker_log_name = 'compliance_checker_log.txt'\n",
    "# Write the checker results once closed/<organization> and once under open/<organization>.\n",
    "for results_dir in [ open_org_results_dir, closed_org_results_dir ]:\n",
    "    checker_log_path = os.path.join(results_dir, checker_log_name)\n",
    "    with open(checker_log_path, 'w') as checker_log_file:\n",
    "        checker_log_file.writelines(checker_log)\n",
    "        print(results_dir)\n",
    "        print('  |_%s' % checker_log_name)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
