{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MLPerf Inference Results v0.5](https://github.com/mlperf/inference/tree/master/v0.5)\n",
    "## Automatic results table generation (c) [dividiti](http://dividiti.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "# import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "# print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "default_dpi = 300\n",
    "default_fontsize = 12\n",
    "mp.rcParams['figure.dpi'] = default_dpi\n",
    "mp.rcParams['font.size'] = default_fontsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to the repository with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the results directory:\n",
    "# git clone https://github.com/mlperf/inference_results_v0.5 <results_path>\n",
    "# or\n",
    "# git clone https://github.com/dividiti/inference_results_v0.5 <results_path>\n",
    "results_path = '/home/anton/projects/mlperf/inference_results_v0.5_dividiti'\n",
    "#results_path = '/home/anton/projects/mlperf/inference_results_v0.5_plus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to the cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_name = 'mlperf-inference-v0.5-results.zip'\n",
    "cache_compression = 'zip'\n",
    "cache_protocol = 2 # Supported since Python 2.3\n",
    "\n",
    "import ck.kernel as ck\n",
    "repo_uoa = 'ck-mlperf'\n",
    "module_uoa = 'module'\n",
    "data_uoa = 'mlperf.inference'\n",
    "r = ck.access({'action':'find', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'data_uoa':data_uoa})\n",
    "if r['return']>0:\n",
    "    print('Error: %s' % r['error'])\n",
    "    exit(1)\n",
    "cache_path = os.path.join(r['path'], cache_name)\n",
    "cache_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions = [ 'closed', 'open' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps for DataFrame construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase or camelcase or camelcase with space to camelcase.\n",
    "scenario_to_str = {\n",
    "    # SingleStream.\n",
    "    'singlestream'  : 'SingleStream',\n",
    "    'SingleStream'  : 'SingleStream',\n",
    "    'Single Stream' : 'SingleStream',\n",
    "    # MultiStream.\n",
    "    'multistream'   : 'MultiStream',\n",
    "    'MultiStream'   : 'MultiStream',\n",
    "    'Multi Stream'  : 'MultiStream',\n",
    "    # Server.\n",
    "    'server'        : 'Server',\n",
    "    'Server'        : 'Server',\n",
    "    # Offline.\n",
    "    'offline'       : 'Offline',\n",
    "    'Offline'       : 'Offline',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_to_str = {\n",
    "    # Open.\n",
    "    'open'   : 'Open',\n",
    "    'Open'   : 'Open',\n",
    "    # Closed.\n",
    "    'closed' : 'Closed',\n",
    "    'Closed' : 'Closed'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividiti-specific.\n",
    "system_id_to_processor = {\n",
    "    'firefly'   : 'Rockchip RK3399',\n",
    "    'hikey960'  : 'HiSilicon Kirin960',\n",
    "    'mate10pro' : 'HiSilicon Kirin970',\n",
    "    'rpi4'      : 'Broadcom BCM2711B0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator_name_to_accelerator = {\n",
    "    'NVIDIA Tesla T4': 'NVIDIA Tesla T4',\n",
    "    'Nvidia Tesla T4': 'NVIDIA Tesla T4',\n",
    "    'Tesla T4': 'NVIDIA Tesla T4',\n",
    "    'Nvidia Tesla V100 SXM3': 'NVIDIA Tesla V100 SXM3',\n",
    "    'tpu-v3.8': 'Google TPU v3-8', # NB: 8 TPU v3?\n",
    "    'HanGuang 800': 'Alibaba HanGuang 800',\n",
    "    'Goya': 'Habana Goya',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for DataFrame construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics: Stream in ms; MultiStream in #streams; Server in QPS; Offline in inputs/s).\n",
    "performance_columns = [\n",
    "    'P_{}_{}'.format(task, scenario)\n",
    "    for task in ['IC1','IC2','OD1','OD2','NMT'] \n",
    "    for scenario in ['SS','MS','S','O']\n",
    "]\n",
    "# Accuracy metrics: Image Classification in Top1, %; Object Detection in mAP, %; Machine Translation in BLUE.\n",
    "accuracy_columns = [\n",
    "    'A_{}_{}'.format(task, scenario)\n",
    "    for task in ['IC1','IC2','OD1','OD2','NMT']\n",
    "    for scenario in ['SS','MS','S','O']\n",
    "]\n",
    "# Score columns.\n",
    "score_columns = performance_columns + accuracy_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-imagenet benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_imagenet_benchmarks = {\n",
    "    # Non-ImageNet benchmarks from the closed division.\n",
    "    'ssd-small': {\n",
    "        \"name\"  : \"SSD-MobileNet-v1\",\n",
    "        \"width\" : 300,\n",
    "        \"height\": 300,\n",
    "    },\n",
    "    'ssd-large': {\n",
    "        \"name\"  : \"SSD-ResNet34\",\n",
    "        \"width\" : 1200,\n",
    "        \"height\": 1200,\n",
    "    },\n",
    "    'gnmt' : {\n",
    "        \"name\"  : \"GNMT\",\n",
    "        \"width\" : -1,\n",
    "        \"height\": -1,\n",
    "    },\n",
    "    # Non-ImageNet benchmarks from the open division.\n",
    "    'rcnn-nas-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-NAS lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1200,\n",
    "        \"height\" : 1200,\n",
    "    },\n",
    "    'rcnn-resnet50-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-ResNet50 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-resnet101-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-ResNet101 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-inception-resnet-v2-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-Inception-ResNet-v2 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-inception-v2' : {\n",
    "        \"name\" : \"Faster-RCNN Inception-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'ssd-inception-v2' : {\n",
    "        \"name\" : \"SSD-Inception-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "    },\n",
    "    'ssd-mobilenet-v1-quantized-mlperf' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1\",\n",
    "        \"url\" : \"https://zenodo.org/record/3361502/files/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "        \"provenance\" : \"Google\",\n",
    "    },\n",
    "    'ssd-mobilenet-v1-non-quantized-mlperf' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1 quantized\",\n",
    "        \"url\" : \"https://zenodo.org/record/3252084/files/mobilenet_v1_ssd_8bit_finetuned.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "        \"provenance\" : \"Habana\"\n",
    "    },\n",
    "    'ssd-mobilenet-v1-fpn' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1 FPN SBP\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\",\n",
    "        \"width\" : 640,\n",
    "        \"height\" : 640,\n",
    "    },\n",
    "    'ssd-resnet50-fpn' : {\n",
    "        \"name\" : \"SSD-ResNet50-v1 FPN SBP\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\",\n",
    "        \"width\" : 640,\n",
    "        \"height\" : 640,\n",
    "    },\n",
    "    'ssdlite-mobilenet-v2' : {\n",
    "        \"name\" : \"SSDLite-MobileNet-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "    },\n",
    "    'yolo-v3' : {\n",
    "        \"name\" : \"YOLO-v3\",\n",
    "        \"url\" : \"https://zenodo.org/record/3386327/files/yolo_v3_coco.tar.gz\",\n",
    "        \"width\" : 416,\n",
    "        \"height\" : 416,\n",
    "        \"provenance\" : \"https://github.com/YunYang1994/tensorflow-yolov3/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use two modes: the 'spreadsheet' mode tries to mimic the official submission table as much as possible;\n",
    "# the 'dashboard' mode uses a more appropriate layout for the CK dashboard.\n",
    "def get_data(results_path=results_path, mode='spreadsheet'):\n",
    "    dfs = []\n",
    "    # FOR EACH division.\n",
    "    for division in divisions:\n",
    "        #if division == 'open': continue # skip\n",
    "        # FOR EACH submitter.\n",
    "        submitters_dir = os.path.join(results_path, division)\n",
    "        submitters = [ fn for fn in os.listdir(submitters_dir) if os.path.isdir(os.path.join(submitters_dir, fn)) ]\n",
    "        for submitter in submitters:\n",
    "            # Selectively filter out submitters.\n",
    "            #all_submitters_closed = [ 'Alibaba', 'CentaurTechnology', 'DellEMC', 'dividiti', 'FuriosaAI', 'Google', 'Habana', 'Hailo', 'Intel', 'NVIDIA', 'Qualcomm', 'Tencent' ]\n",
    "            #if division == 'closed' and submitter not in all_submitters_closed: continue\n",
    "            #all_submitters_open = [ 'dividiti', 'Habana', 'Inspur', 'NVIDIA', 'Qualcomm' ]\n",
    "            #if division == 'open' and submitter not in all_submitters_open: continue\n",
    "            # FOR EACH system.\n",
    "            results_dir = os.path.join(submitters_dir, submitter, 'results')\n",
    "            systems = [ fn for fn in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, fn)) ]\n",
    "            for system in systems:\n",
    "                system_dir = os.path.join(results_dir, system)\n",
    "                system_json_name = system + '.json'\n",
    "                system_json_path = os.path.join(submitters_dir, submitter, 'systems', system_json_name)\n",
    "                with open(system_json_path) as system_json_file:\n",
    "                    system_json = json.load(system_json_file)\n",
    "\n",
    "                # Category.\n",
    "                if system_json['status'] in [ 'available', 'Available' ]:\n",
    "                    category = 'Available'\n",
    "                elif system_json['status'] in [ 'preview', 'Preview' ]:\n",
    "                    category = 'Preview'\n",
    "                elif system_json['status'] in [ 'rdi', 'RDI', 'rdo', 'RDO' ]:\n",
    "                    category = 'Research, Development, Other'\n",
    "                elif system_json['status'] in [ 'Unofficial', 'unofficial' ]:\n",
    "                    category = 'Unofficial'\n",
    "                else:\n",
    "                    raise Exception(\"Unsupported category '%s'!\" % (system_json['status']))\n",
    "\n",
    "                # System details.\n",
    "                system_name = system_json['system_name']\n",
    "                system_list = system.split('-')\n",
    "                system_id = system_list[0]                \n",
    "\n",
    "                # Processor (CPU).\n",
    "                processor = system_id_to_processor.get(system_id, system_json.get('host_processor_model_name', 'N/A'))\n",
    "                processor_num = int(system_json.get('host_processors_per_node', 0))\n",
    "\n",
    "                # Accelerator.\n",
    "                # Tencent: https://github.com/mlperf/submissions_inference_0_5/issues/285\n",
    "                accelerator_name = system_json.get('accelerator_model_name', 'N/A')\n",
    "                accelerator_num = int(system_json.get('accelerators_per_node', 0))\n",
    "                accelerator = accelerator_name_to_accelerator.get(accelerator_name, accelerator_name)\n",
    "\n",
    "                # Software (framework).\n",
    "                software = system_json['framework']\n",
    "\n",
    "                # Default form factors and notes.\n",
    "                # NB: Using space rather than empty string turns out better for dashboard.\n",
    "                ff_m = ff_d = ff_s = ff_e = ' '\n",
    "                notes = ' '\n",
    "\n",
    "                # Submitter-specific form factors and notes.\n",
    "                submitter_str = submitter\n",
    "                if submitter == 'dividiti':\n",
    "                    # Form factors.\n",
    "                    if system_id in [ 'hikey960', 'firefly', 'rpi4' ]: ff_e = 'x'\n",
    "                    if system_id in [ 'mate10pro', 'hikey960' ]: ff_m = 'x'\n",
    "                    if system_id in [ 'velociti' ]: ff_d = 'x'\n",
    "                    # Notes.\n",
    "                    if system_id == 'hikey960':\n",
    "                        notes = 'Mobile chip in embedded form factor (development board).'\n",
    "                    if division == 'open':\n",
    "                        # Object Detection is collaboration between dividiti and Politecnico di Milano.\n",
    "                        if system_id == 'velociti': submitter_str = 'dividiti + PoliMi'\n",
    "                        if system == 'velociti-tensorflow-v1.14-cpu':\n",
    "                            notes = 'In the Other category, since this Intel CPU is no longer available (end-of-life).'\n",
    "                elif submitter == 'Alibaba':\n",
    "                    ff_s = 'x'\n",
    "                    if system_id == 'alibaba_cloud_t4':\n",
    "                        notes = 'ECC off'\n",
    "                elif submitter == 'DellEMC':\n",
    "                    ff_s = 'x'\n",
    "                    if system_id == 'R740_T4x4_tensorrt':\n",
    "                        notes = 'ECC off'\n",
    "                elif submitter == 'Google':\n",
    "                    ff_s = 'x'\n",
    "                    system_name = '{:d}x Cloud {:s}'.format(int(accelerator_num/8), accelerator)\n",
    "                elif submitter == 'Habana':\n",
    "                    ff_d = ff_s = ff_e = 'x'\n",
    "                    if division == 'open':\n",
    "                        if system_id == 'Goya_fast_latency':\n",
    "                            notes = 'Low latency results ...'\n",
    "                        if system_id == 'Goya_med_latency':\n",
    "                            notes = 'Medium latency results ...'  \n",
    "                elif submitter == 'Intel':\n",
    "                    if system_id == 'ICL':\n",
    "                        ff_m = 'x'\n",
    "                    else:\n",
    "                        ff_s = 'x'\n",
    "                elif submitter == 'NVIDIA':\n",
    "                    if system_id == 'Xavier':\n",
    "                        ff_e = 'x'\n",
    "                        if division == 'closed':\n",
    "                            notes = 'GPU and both DLAs are used in Offline and MultiStream'\n",
    "                    elif system_id == 'TitanRTXx4':\n",
    "                        ff_e = ff_s = ff_d = 'x'\n",
    "                    elif system_id == 'T4x8':\n",
    "                        ff_e = ff_s = 'x'\n",
    "                    elif system_id == 'T4x20':\n",
    "                        ff_s = 'x'\n",
    "                    else:\n",
    "                        raise Exception(\"Unsupported NVIDIA system '%s'!\" % system_id)                    \n",
    "                elif submitter == 'Qualcomm':\n",
    "                    ff_m = 'x'\n",
    "                    if division == 'open':\n",
    "                        notes = 'Median latency. MultiStream: Both Hexagon Vector Extensions (HVX) and Hexagon Tensor Accelerator (HTA).'\n",
    "                    if division == 'closed':\n",
    "                        notes = 'Hexagon Vector Extensions being used.'\n",
    "                elif submitter == 'Tencent':\n",
    "                    ff_s = 'x'\n",
    "                # Preview only.\n",
    "                elif submitter == 'CentaurTechnology':\n",
    "                    ff_d = ff_s = ff_e = 'x'\n",
    "                elif submitter == 'Hailo':\n",
    "                    ff_d = ff_e = 'x'\n",
    "                # RDO only.\n",
    "                elif submitter == 'FuriosaAI':\n",
    "                    ff_d = ff_s = ff_e = 'x'\n",
    "                # Open only.\n",
    "                elif submitter == 'Inspur':\n",
    "                    ff_s = 'x'\n",
    "                else:\n",
    "                    raise Exception(\"Unsupported division/submitter combination '%s'/'%s'!\" % (division, submitter))\n",
    "\n",
    "                # Create DataFrame for each row of the final table based on the division, submitter and system.\n",
    "                data = [{\n",
    "                    # \n",
    "                    'ID'            : '-', # TODO: Fill in later.\n",
    "                    'Submitter'     : submitter_str,\n",
    "                    'System'        : system_name,\n",
    "                    'Benchmark'     : '-', # TODO: Fill in later.\n",
    "                    # Processor.\n",
    "                    'Processor'     : processor,\n",
    "                    'Processor #'   : processor_num,\n",
    "                    # Accelerator.\n",
    "                    'Accelerator'   : accelerator,\n",
    "                    'Accelerator #' : accelerator_num if accelerator_num != '0' else '',\n",
    "                    # Software.\n",
    "                    'Software' : software,\n",
    "                    # Form factor.\n",
    "                    'FF_M'     : ff_m,\n",
    "                    'FF_D'     : ff_d,\n",
    "                    'FF_S'     : ff_s,\n",
    "                    'FF_E'     : ff_e,\n",
    "                    # Details. Code. Notes.\n",
    "                    'Details'  : 'https://github.com/mlperf/inference_results_v0.5/blob/master/{}/{}/systems/{}'. \\\n",
    "                                        format(division, submitter, system_json_name),\n",
    "                    'Code'     : 'https://github.com/mlperf/inference_results_v0.5/tree/master/{}/{}/code'. \\\n",
    "                                        format(division, submitter),\n",
    "                    'Notes'    : notes,\n",
    "                    # Misc.\n",
    "                    'Division' : division_to_str.get(division, division),\n",
    "                    'Category' : category,\n",
    "                    'Task'     : '-', # TODO: Fill in later.\n",
    "                    'Scenario' : '-', # TODO: Fill in later.\n",
    "                }]\n",
    "                # NB: 'Accelerator #' is important to sort Google's submissions correctly (not lexicographically).\n",
    "                index = [\n",
    "                    'Division', 'Category', 'Submitter', 'Accelerator #', 'System', 'Software', 'Benchmark' #, 'Task', 'Scenario'\n",
    "                ]\n",
    "                # Reset all scores.\n",
    "                if mode == 'spreadsheet':\n",
    "                    data[0].update({ score : '' for score in score_columns })\n",
    "\n",
    "                # FOR EACH benchmark.\n",
    "                benchmarks = [ fn for fn in os.listdir(system_dir) if os.path.isdir(os.path.join(system_dir, fn)) ]\n",
    "                for (benchmark, benchmark_idx) in zip(benchmarks, range(len(benchmarks))):\n",
    "                    is_last_benchmark = (benchmark_idx == len(benchmarks) - 1)\n",
    "                    # Tencent and Inspur use resnet50.\n",
    "                    benchmark_name = 'resnet' if benchmark == 'resnet50' else benchmark\n",
    "                    # Benchmark (with notes).\n",
    "                    benchmark_dict = non_imagenet_benchmarks.get(benchmark_name)\n",
    "                    if benchmark_dict:\n",
    "                        width = benchmark_dict['width']\n",
    "                        height = benchmark_dict['height']\n",
    "                    else:\n",
    "                        if benchmark_name.endswith('96'):\n",
    "                            side = 96\n",
    "                        elif benchmark_name.endswith('128'):\n",
    "                            side = 128\n",
    "                        elif benchmark_name.endswith('160'):\n",
    "                            side = 160\n",
    "                        elif benchmark_name.endswith('192'):\n",
    "                            side = 192\n",
    "                        else:\n",
    "                            side = 224\n",
    "                        width = side\n",
    "                        height = side\n",
    "                    if width != -1 and height != -1:\n",
    "                        # Benchmark (width x height).\n",
    "                        benchmark_with_notes = '{} ({}x{})'.format(benchmark_name, width, height)\n",
    "                    else:\n",
    "                        # GNMT.\n",
    "                        benchmark_with_notes = benchmark_name\n",
    "                    # TODO: Rename to 'Model used, if not Closed Division default' for Open.\n",
    "                    data[0]['Benchmark'] = benchmark_with_notes\n",
    "\n",
    "                    # FOR EACH scenario.\n",
    "                    benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "                    scenarios = [ fn for fn in os.listdir(benchmark_dir) if os.path.isdir(os.path.join(benchmark_dir, fn)) ]\n",
    "                    for scenario in scenarios:\n",
    "                        if mode != 'spreadsheet':\n",
    "                            data[0].update({ score : '' for score in score_columns })\n",
    "                        scenario_str = scenario_to_str.get(scenario,'')\n",
    "                        if scenario_str not in [ 'SingleStream', 'MultiStream', 'Server', 'Offline' ]: continue\n",
    "                        experiment_dir = os.path.join(benchmark_dir, scenario)\n",
    "                        # Extract accuracy.\n",
    "                        if submitter == 'Hailo' and benchmark == 'ssd-small':\n",
    "                            # https://github.com/mlperf/submissions_inference_0_5/issues/287\n",
    "                            task = 'OD'\n",
    "                            accuracy = 21.920 # ssd-small/SingleStream/accuracy/results.json\n",
    "                        else:\n",
    "                            accuracy_dir = os.path.join(experiment_dir, 'accuracy')\n",
    "                            with open(os.path.join(accuracy_dir, 'accuracy.txt'), 'r') as accuracy_file:\n",
    "                                accuracy_txt = accuracy_file.readlines()\n",
    "                                accuracy_line = accuracy_txt[-1]\n",
    "                            if accuracy_line.startswith('mAP'):\n",
    "                                task = 'OD'\n",
    "                                match = re.match('mAP\\=([\\d\\.]+)\\%', accuracy_line)\n",
    "                                accuracy = float(match.group(1))\n",
    "                            elif accuracy_line.startswith('accuracy'):\n",
    "                                task = 'IC'\n",
    "                                match = re.match('accuracy=(.+)%, good=(\\d+), total=(\\d+)', accuracy_line)\n",
    "                                accuracy = float(match.group(1))\n",
    "                            elif accuracy_line.startswith('BLEU'):\n",
    "                                task = 'MT'\n",
    "                                match = re.match('BLEU:\\s*(.+)', accuracy_line)\n",
    "                                accuracy = float(match.group(1))\n",
    "                            else:\n",
    "                                pprint(accuracy_txt)\n",
    "                                raise Exception('Failed to extract accuracy information from \"%s\"' % accuracy_line)\n",
    "                        data[0]['Task'] = { 'IC': 'Image Classification', 'OD': 'Object Detection', 'MT': 'Machine Translation' }.get(task)\n",
    "                                \n",
    "                        if scenario_str in [ 'SingleStream', 'MultiStream', 'Offline', 'Server' ]:\n",
    "                            data[0]['Scenario'] = scenario_to_str.get(scenario, scenario)\n",
    "                            if submitter == 'Tencent' and scenario_str in [ 'SingleStream', 'Offline' ]:\n",
    "                                # https://github.com/mlperf/submissions_inference_0_5/issues/286\n",
    "                                performance_dir = os.path.join(experiment_dir, 'performance')\n",
    "                            else:\n",
    "                                # TODO: Iterate over 5 runs for Server.\n",
    "                                performance_dir = os.path.join(experiment_dir, 'performance', 'run_1')                            \n",
    "                            with open(os.path.join(performance_dir, 'mlperf_log_summary.txt'), 'r') as summary_file:\n",
    "                                summary_txt = summary_file.readlines()\n",
    "                                for line in summary_txt:\n",
    "                                    if re.match(\"Scenario\", line):\n",
    "                                        # NB: LoadGen scenario strings have spaces between 'Single'/'Multi' and 'Stream'.\n",
    "                                        loadgen_scenario = line.split(\": \",1)[1].strip()\n",
    "                                        loadgen_scenario_str = scenario_to_str[loadgen_scenario]\n",
    "                                        if loadgen_scenario_str != scenario_str:\n",
    "                                            raise Exception(\"Expected '%s', parsed '%s'!\" % (scenario_str, loadgen_scenario_str ))\n",
    "                                        continue\n",
    "                                    if scenario_str == \"SingleStream\":\n",
    "                                        if re.match(\"90th percentile latency\", line):\n",
    "                                            score = line.split(\": \",1)[1].strip()\n",
    "                                            continue\n",
    "                                    if scenario_str == \"MultiStream\":\n",
    "                                        if re.match(\"Samples per query\", line):\n",
    "                                            score = line.split(\": \",1)[1].strip()\n",
    "                                            continue\n",
    "                                    if scenario_str == \"Server\":\n",
    "                                        if re.match(\"Scheduled samples per second\", line):\n",
    "                                            score = line.split(\": \",1)[1].strip()\n",
    "                                            continue\n",
    "                                    if scenario_str == \"Offline\":\n",
    "                                        if re.match(\"Samples per second\", line):\n",
    "                                            score = line.split(\": \",1)[1].strip()\n",
    "                                            continue\n",
    "                            if scenario_str == 'SingleStream':\n",
    "                                time_ns = int(score)\n",
    "                                time_ms = time_ns * 1e-6\n",
    "                            elif scenario_str == 'MultiStream':\n",
    "                                num_streams = int(score)\n",
    "                            elif scenario_str == 'Server':\n",
    "                                queries_per_second = float(score)\n",
    "                            elif scenario_str == 'Offline':\n",
    "                                samples_per_second = float(score)\n",
    "                        else:\n",
    "                            raise Exception(\"Unsupported scenario '%s'!\" % scenario_str)\n",
    "\n",
    "                        # Tasks.\n",
    "                        if mode == 'spreadsheet':                        \n",
    "                            ic1 = (task=='IC' and benchmark.startswith('mobilenet'))\n",
    "                            ic2 = (task=='IC' and benchmark.startswith('resnet'))\n",
    "                            od1 = (task=='OD' and benchmark=='ssd-small')\n",
    "                            od2 = (task=='OD' and (benchmark=='ssd-large' or system_id=='velociti'))\n",
    "                            nmt = (task=='MT')\n",
    "                        else:\n",
    "                            ic1 = (task=='IC')\n",
    "                            ic2 = False\n",
    "                            od1 = (task=='OD')\n",
    "                            od2 = False\n",
    "                            nmt = (task=='MT')\n",
    "                        if scenario_str == 'SingleStream':\n",
    "                            performance_str = '{:.03f}'.format(time_ms)\n",
    "                            accuracy_str    = '{:.03f}'.format(accuracy)\n",
    "                            if ic1:\n",
    "                                data[0]['A_IC1_SS'] = accuracy_str\n",
    "                                data[0]['P_IC1_SS'] = performance_str\n",
    "                            elif ic2:\n",
    "                                data[0]['A_IC2_SS'] = accuracy_str\n",
    "                                data[0]['P_IC2_SS'] = performance_str\n",
    "                            elif od1:\n",
    "                                data[0]['A_OD1_SS'] = accuracy_str\n",
    "                                data[0]['P_OD1_SS'] = performance_str\n",
    "                            elif od2:\n",
    "                                data[0]['A_OD2_SS'] = accuracy_str\n",
    "                                data[0]['P_OD2_SS'] = performance_str\n",
    "                            elif nmt:\n",
    "                                data[0]['A_NMT_SS'] = accuracy_str\n",
    "                                data[0]['P_NMT_SS'] = performance_str\n",
    "                        elif scenario_str == 'MultiStream':\n",
    "                            performance_str = '{:d}'.format(num_streams)\n",
    "                            accuracy_str    = '{:.03f}'.format(accuracy)\n",
    "                            if ic1:\n",
    "                                data[0]['A_IC1_MS'] = accuracy_str\n",
    "                                data[0]['P_IC1_MS'] = performance_str\n",
    "                            elif ic2:\n",
    "                                data[0]['A_IC2_MS'] = accuracy_str\n",
    "                                data[0]['P_IC2_MS'] = performance_str\n",
    "                            elif od1:\n",
    "                                data[0]['A_OD1_MS'] = accuracy_str\n",
    "                                data[0]['P_OD1_MS'] = performance_str\n",
    "                            elif od2:\n",
    "                                data[0]['A_OD2_MS'] = accuracy_str\n",
    "                                data[0]['P_OD2_MS'] = performance_str\n",
    "                            elif nmt:\n",
    "                                data[0]['A_NMT_MS'] = accuracy_str\n",
    "                                data[0]['P_NMT_MS'] = performance_str\n",
    "                        elif scenario_str == 'Server':\n",
    "                            performance_str = '{:.03f}'.format(queries_per_second)\n",
    "                            accuracy_str    = '{:.03f}'.format(accuracy)\n",
    "                            if ic1:\n",
    "                                data[0]['A_IC1_S'] = accuracy_str\n",
    "                                data[0]['P_IC1_S'] = performance_str\n",
    "                            elif ic2:\n",
    "                                data[0]['A_IC2_S'] = accuracy_str\n",
    "                                data[0]['P_IC2_S'] = performance_str\n",
    "                            elif od1:\n",
    "                                data[0]['A_OD1_S'] = accuracy_str\n",
    "                                data[0]['P_OD1_S'] = performance_str\n",
    "                            elif od2:\n",
    "                                data[0]['A_OD2_S'] = accuracy_str\n",
    "                                data[0]['P_OD2_S'] = performance_str\n",
    "                            elif nmt:\n",
    "                                data[0]['A_NMT_S'] = accuracy_str\n",
    "                                data[0]['P_NMT_S'] = performance_str                            \n",
    "                        elif scenario_str == 'Offline':\n",
    "                            performance_str = '{:.03f}'.format(samples_per_second)\n",
    "                            accuracy_str    = '{:.03f}'.format(accuracy)\n",
    "                            if ic1:\n",
    "                                data[0]['A_IC1_O'] = accuracy_str\n",
    "                                data[0]['P_IC1_O'] = performance_str\n",
    "                            elif ic2:\n",
    "                                data[0]['A_IC2_O'] = accuracy_str\n",
    "                                data[0]['P_IC2_O'] = performance_str\n",
    "                            elif od1:\n",
    "                                data[0]['A_OD1_O'] = accuracy_str\n",
    "                                data[0]['P_OD1_O'] = performance_str\n",
    "                            elif od2:\n",
    "                                data[0]['A_OD2_O'] = accuracy_str\n",
    "                                data[0]['P_OD2_O'] = performance_str\n",
    "                            elif nmt:\n",
    "                                data[0]['A_NMT_O'] = accuracy_str\n",
    "                                data[0]['P_NMT_O'] = performance_str\n",
    "                        else:\n",
    "                            print('Skipping unsupported task/scenario combination!')\n",
    "                            continue\n",
    "                        if mode != 'spreadsheet':\n",
    "                            df = pd.DataFrame(data)\n",
    "                            df = df.set_index(index)\n",
    "                            dfs.append(df)\n",
    "                    # END OF FOR EACH scenario\n",
    "                    if mode == 'spreadsheet':\n",
    "                        # For closed, multiple benchmarks can share the same row, so the Benchmark field can be misleading.\n",
    "                        if division == 'closed': data[0]['Benchmark'] = ''\n",
    "                        if is_last_benchmark or (division == 'open' and submitter == 'dividiti'):\n",
    "                            df = pd.DataFrame(data)\n",
    "                            df = df.set_index(index)\n",
    "                            dfs.append(df)\n",
    "                    # For the spreadsheet mode, include multiple benchmarks per row.\n",
    "                # END OF FOR EACH benchmark\n",
    "            # END OF FOR EACH system\n",
    "        # END OF FOR EACH submitter\n",
    "    # END OF FOR EACH division\n",
    "    \n",
    "    # Concatenate all thus constructed DataFrames (i.e. stack on top of each other).\n",
    "    df = pd.concat(dfs)\n",
    "    # Temporarily capitalize the first letter in 'dividiti' for correct sorting and then back.\n",
    "    df = df \\\n",
    "        .rename(index={'dividiti':'Dividiti', 'dividiti + PoliMi':'Dividiti + PoliMi'}) \\\n",
    "        .sort_index(ascending=True) \\\n",
    "        .rename(index={'Dividiti':'dividiti', 'Dividiti + PoliMi':'dividiti + PoliMi'}) \\\n",
    "    \n",
    "    # Reset the index, but keep Division and Category there.\n",
    "    df = df.reset_index(level=index[2:])\n",
    "    df['ID'] = [ 'Inf-0.5-{:03d}'.format(ID) for ID in range(1, len(df)+1) ]\n",
    "    # Mimic the official template.\n",
    "    columns = [ 'ID', 'Submitter', 'System', 'Benchmark' ]\n",
    "    columns += score_columns\n",
    "    columns += [ 'Processor', 'Processor #', 'Accelerator', 'Accelerator #', 'Software',\n",
    "                'FF_M', 'FF_D', 'FF_S', 'FF_E', 'Details', 'Code', 'Notes' ]\n",
    "    # Finalize the table.\n",
    "    if mode == 'spreadsheet':\n",
    "        df = df[columns]\n",
    "    else:\n",
    "        df = df.reset_index().set_index(keys=[ 'ID', 'Division', 'Category', 'Submitter', 'System', 'Benchmark' ], drop=False)\n",
    "        df[score_columns] = df[score_columns].apply(pd.to_numeric).astype('float32')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(results_path=results_path, mode='spreadsheet')\n",
    "display_in_full(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump the table for the CK dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always clean the cache while in the development mode.\n",
    "!rm -f $cache_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(cache_path):\n",
    "    # Load the table from cache.\n",
    "    print('Loading the results table from cache ...')\n",
    "    df = pd.read_pickle(cache)\n",
    "else:\n",
    "    # Store the table in a simplified format.\n",
    "    print('Storing the results table to cache ...')\n",
    "    df = get_data(results_path=results_path, mode='dashboard')\n",
    "    df.to_pickle(path=cache_path, protocol=cache_protocol, compression=cache_compression)\n",
    "display_in_full(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump the table into Excel (with separate sheets for Division / Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "from pandas import ExcelWriter\n",
    "# NB: Cannot use dot for 'v0.5', as otherwise the engine complains about an unknown extension.\n",
    "xlsx_filename = 'MLPerf Inference v0_5 - Results (Automatically Generated).xlsx'\n",
    "xlsx_writer = ExcelWriter(xlsx_filename, engine='xlsxwriter', options={'strings_to_urls': True})\n",
    "df_ = df.droplevel('ID')\n",
    "for division in df.index.unique(level='Division'):\n",
    "    df_d = df_.loc[division]\n",
    "    for category in df_d.index.unique(level='Category'):\n",
    "        df_dc = df_d.loc[category]\n",
    "        if division == 'Open':\n",
    "            df_xlsx = df_dc\n",
    "        elif division == 'Closed':\n",
    "            df_xlsx = df_dc.drop(labels=['Benchmark']+accuracy_columns, axis=1)\n",
    "        else:\n",
    "            continue\n",
    "        # Write different division and category results to separate sheets. Omit index.\n",
    "        print('*' * 100)\n",
    "        print('* Division / Category: %s / %s' % (division, category))\n",
    "        print('*' * 100)\n",
    "        if category == 'Research, Development, Other': category = 'RDO' # NB: sheet_name must be =< 31 symbols.\n",
    "        df_xlsx.to_excel(xlsx_writer, sheet_name='{} - {}'.format(division, category), index=False)\n",
    "        display_in_full(df_xlsx)\n",
    "        print('')\n",
    "xlsx_writer.save()\n",
    "!cp \"$xlsx_filename\" ~/Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance columns are strings for formatting reasons. Convert the strings to numbers (with NaNs for empty strings),\n",
    "# then count the numbers across the columns and finally sum.\n",
    "print(\"#Results: %d\" % df[performance_columns].apply(pd.to_numeric).count(numeric_only=True, axis=0).sum())\n",
    "#print(\"#Results/Closed: %d\" % df.loc['Closed'][performance_columns].apply(pd.to_numeric).count(numeric_only=True, axis=0).sum())\n",
    "#print(\"#Results/Open: %d\" % df.loc['Open'][performance_columns].apply(pd.to_numeric).count(numeric_only=True, axis=0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of results per division per submitter per benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [ 'Division', 'Submitter' ]\n",
    "df_num_results_per_division_per_submitter_per_benchmark = df \\\n",
    "    .reset_index(drop=True) \\\n",
    "    [indices + performance_columns] \\\n",
    "    .set_index(indices) \\\n",
    "    .apply(pd.to_numeric) \\\n",
    "    .groupby(level=indices).count()\n",
    "# display_in_full(df_num_results_per_division_per_submitter_per_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_results_per_division_per_submitter = df_num_results_per_division_per_submitter_per_benchmark.sum(axis=1)\n",
    "df_num_results_per_division_per_submitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_results(df_num_results_per_submitter, autopct='%1.0f%%', pctdistance=0.8, labeldistance=1.1, topN=5,\n",
    "                     explode_submitters=['dividiti'], explode_distance=0.05, startangle=0, shadow=False,\n",
    "                     title='MLPerf Inference v0.5 - Results per Submitter', fname=None, ftype='jpg', color='darkgray'):\n",
    "\n",
    "    df_num_results_per_submitter_descending = pd.DataFrame({\n",
    "        'Submitter' : df_num_results_per_submitter.index,\n",
    "        '#Results'  : df_num_results_per_submitter.values}) \\\n",
    "        .sort_values('#Results', ascending=False)\n",
    "\n",
    "    df_num_results_per_submitter_topN = df_num_results_per_submitter_descending[:topN].copy()\n",
    "\n",
    "    df_num_results_per_submitter_others = pd.DataFrame(data = {\n",
    "        'Submitter' : ['Others'],\n",
    "        '#Results'  : [df_num_results_per_submitter_descending['#Results'][topN:].sum()]})\n",
    "\n",
    "    df_num_results_per_submitter_topN_and_others = \\\n",
    "        pd.concat([df_num_results_per_submitter_topN, df_num_results_per_submitter_others]) \\\n",
    "        .set_index('Submitter') \\\n",
    "        .sort_values('Submitter', ascending=False)\n",
    "\n",
    "    results = df_num_results_per_submitter_topN_and_others['#Results']\n",
    "    submitters = df_num_results_per_submitter_topN_and_others.index\n",
    "    explode = [ explode_distance if submitter in explode_submitters else 0 for submitter in submitters ]\n",
    "\n",
    "    mp.rcParams['figure.dpi'] = default_dpi\n",
    "    plt.pie(results, labels=submitters, autopct=autopct,\n",
    "            pctdistance=pctdistance, labeldistance=labeldistance,\n",
    "            explode=explode, startangle=35, shadow=shadow)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if fname is not None:\n",
    "        # A lazy way to use the default file name.\n",
    "        if fname == '': fname = '{}.{}'.format(title, ftype)    \n",
    "        plt.savefig(fname=fname, format=ftype, dpi=200, quality=95, optimize=True, bbox_inches='tight',\n",
    "                    facecolor=color, edgecolor=color, transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot by division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for division, topN in zip([ 'Closed', 'Open' ], [ 10, 3 ]):\n",
    "#     explode_submitters = [] if division == 'Open' else ['dividiti']\n",
    "#     plot_num_results(\n",
    "#         df_num_results_per_division_per_submitter.loc[division],\n",
    "#         title='MLPerf Inference v0.5 - {} Division - Results per Submitter'.format(division),\n",
    "#         topN=topN, explode_submitters=explode_submitters\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_results(\n",
    "    df_num_results_per_division_per_submitter.droplevel('Division').groupby(level='Submitter').sum(),\n",
    "    topN=8, explode_submitters=['dividiti', 'dividiti + PoliMi'], color='white', fname='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display HTML with embedded links (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.set_index(['Submitter', 'System', 'Benchmark', 'Software'], append=True)\n",
    "# def link_code(url): return '<a target=\"_blank\" href=\"{}\">Code</a>'.format(url)\n",
    "# def link_details(url): return '<a target=\"_blank\" href=\"{}\">Details</a>'.format(url)\n",
    "# display_in_full(df.style.format({'Code': link_code, 'Details': link_details}))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
