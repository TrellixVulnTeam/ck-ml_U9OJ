{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MLPerf Inference Results v0.5](https://github.com/mlperf/inference/tree/master/v0.5)\n",
    "## Automatic results table generation (c) [dividiti](http://dividiti.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "# import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "# print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "default_dpi = 300\n",
    "default_fontsize = 12\n",
    "mp.rcParams['figure.dpi'] = default_dpi\n",
    "mp.rcParams['font.size'] = default_fontsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions = [ 'closed', 'open' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default `system_desc_id.json` (to catch uninitialized descriptions)\n",
    "default_system_json = {\n",
    "    \"division\": \"required\",\n",
    "    \"submitter\": \"required\",\n",
    "    \"status\": \"required\",\n",
    "    \"system_name\": \"required\",\n",
    "\n",
    "    \"number_of_nodes\": \"required\",\n",
    "    \"host_processor_model_name\": \"required\",\n",
    "    \"host_processors_per_node\": \"required\",\n",
    "    \"host_processor_core_count\": \"required\",\n",
    "    \"host_processor_frequency\": \"\",\n",
    "    \"host_processor_caches\": \"\",\n",
    "    \"host_memory_configuration\": \"\",\n",
    "    \"host_memory_capacity\": \"required\",\n",
    "    \"host_storage_capacity\": \"required\",\n",
    "    \"host_storage_type\": \"required\",\n",
    "    \"host_processor_interconnect\": \"\",\n",
    "    \"host_networking\": \"\",\n",
    "    \"host_networking_topology\": \"\",\n",
    "\n",
    "    \"accelerators_per_node\": \"required\",\n",
    "    \"accelerator_model_name\": \"required\",\n",
    "    \"accelerator_frequency\": \"\",\n",
    "    \"accelerator_host_interconnect\": \"\",\n",
    "    \"accelerator_interconnect\": \"\",\n",
    "    \"accelerator_interconnect_topology\": \"\",\n",
    "    \"accelerator_memory_capacity\": \"required\",\n",
    "    \"accelerator_memory_configuration\": \"\",\n",
    "    \"accelerator_on-chip_memories\": \"\",\n",
    "    \"cooling\": \"\",\n",
    "    \"hw_notes\": \"\",\n",
    "\n",
    "    \"framework\": \"required\",\n",
    "    \"operating_system\": \"required\",\n",
    "    \"other_software_stack\": \"required\",\n",
    "    \"sw_notes\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps for DataFrame construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_to_str = {\n",
    "    # Open.\n",
    "    'open'   : 'Open',\n",
    "    'Open'   : 'Open',\n",
    "    # Closed.\n",
    "    'closed' : 'Closed',\n",
    "    'Closed' : 'Closed'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://github.com/mlperf/inference_results_v0.5\n",
    "#results_path = '/home/anton/projects/mlperf/inference_results_v0.5'\n",
    "results_path = '/home/anton/projects/mlperf/submissions_inference_0_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "# FOR EACH division.\n",
    "for division in divisions:\n",
    "    #if division == 'open': continue # skip\n",
    "    # FOR EACH submitter.\n",
    "    submitters_dir = os.path.join(results_path, division)\n",
    "    submitters = [ fn for fn in os.listdir(submitters_dir) if os.path.isdir(os.path.join(submitters_dir, fn)) ]\n",
    "    for submitter in submitters:\n",
    "        # Selectively filter out submitters.\n",
    "        #all_submitters_closed = [ 'Alibaba', 'CentaurTechnology', 'DellEMC', 'dividiti', 'FuriosaAI', 'Google', 'Habana', 'Hailo', 'Intel', 'NVIDIA', 'Qualcomm', 'Tencent' ]\n",
    "        #if division == 'closed' and submitter not in all_submitters_closed: continue\n",
    "        #all_submitters_open = [ 'dividiti', 'Habana', 'Inspur', 'NVIDIA', 'Qualcomm' ]\n",
    "        #if division == 'open' and submitter not in all_submitters_open: continue\n",
    "        # FOR EACH system.\n",
    "        results_dir = os.path.join(submitters_dir, submitter, 'results')\n",
    "        systems = [ fn for fn in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, fn)) ]\n",
    "        for system in systems:\n",
    "            system_dir = os.path.join(results_dir, system)\n",
    "            system_json_name = system + '.json'\n",
    "            system_json_path = os.path.join(submitters_dir, submitter, 'systems', system_json_name)\n",
    "            with open(system_json_path) as system_json_file:\n",
    "                system_json = json.load(system_json_file)\n",
    "            \n",
    "            # Validate division.\n",
    "            division_from_system_json = system_json.get('division')\n",
    "            if division_from_system_json == None:\n",
    "                print(\"[WARNING] no division key in {}\".format(system_json_name))\n",
    "            if division_from_system_json != division:\n",
    "                print(\"[WARNING] bad division key in {}: {} != {}\".format(system_json_name, division_from_system_json, division))\n",
    "            # Validate submitter.\n",
    "            submitter_from_system_json = system_json.get('submitter')\n",
    "            if submitter_from_system_json == None:\n",
    "                print(\"[WARNING] no submitter key in {}\".format(system_json_name))\n",
    "            if submitter_from_system_json != submitter:\n",
    "                print(\"[WARNING] bad submitter key in {}: {} != {}\".format(system_json_name, submitter_from_system_json, submitter))\n",
    "            # Create DataFrame for each row of the final table.\n",
    "            data = [{\n",
    "                'JSON' : system_json_name,\n",
    "                'URL' : 'https://github.com/mlperf/inference_results_v0.5/blob/master/{}/{}/systems/{}'. \\\n",
    "                format(division, submitter, system_json_name)\n",
    "            }]\n",
    "            for key in default_system_json.keys():\n",
    "                data[0][key] = system_json.get(key, 'NO_KEY')\n",
    "            index = [\n",
    "                'JSON'\n",
    "            ]\n",
    "            df = pd.DataFrame(data)\n",
    "            df = df.set_index(index)\n",
    "            dfs.append(df)\n",
    "        # END OF FOR EACH system\n",
    "    # END OF FOR EACH submitter\n",
    "# END OF FOR EACH division\n",
    "\n",
    "# Concatenate all thus constructed DataFrames (i.e. stack on top of each other).\n",
    "df = pd.concat(dfs)\n",
    "display_in_full(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump Excel (into separate sheets for different system keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "from pandas import ExcelWriter\n",
    "# NB: Cannot use dot for 'v0.5', as otherwise the engine complains about an unknown extension.\n",
    "xlsx_filename = 'MLPerf Inference v0_5 - Systems (Automatically Generated).xlsx'\n",
    "xlsx_writer = ExcelWriter(xlsx_filename, engine='xlsxwriter', options={'strings_to_urls': True})\n",
    "# Write the DataFrame to one sheet and the transposed DataFrame to another.\n",
    "df.to_excel(xlsx_writer, sheet_name='ALL', index=True)\n",
    "df.T.to_excel(xlsx_writer, sheet_name='ALL-TRANSPOSED', index=True)\n",
    "# Write different system keys to different sheets.\n",
    "for key in df.columns:\n",
    "    if key == 'URL': continue\n",
    "    print('*' * 100)\n",
    "    print('* Key: %s' % (key))\n",
    "    print('*' * 100)\n",
    "    df_xlsx = df[[key,'URL']]\n",
    "    # Limit sheet name to 31 symbols. Do not omit index (JSON).\n",
    "    df_xlsx.to_excel(xlsx_writer, sheet_name='{}'.format(key[:31]), index=True)\n",
    "    display_in_full(df_xlsx)\n",
    "    print('')\n",
    "xlsx_writer.save()\n",
    "!cp \"$xlsx_filename\" ~/Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display HTML with embedded links (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.set_index(['Submitter', 'System', 'Benchmark', 'Software'], append=True)\n",
    "# def link_code(url): return '<a target=\"_blank\" href=\"{}\">Code</a>'.format(url)\n",
    "# def link_details(url): return '<a target=\"_blank\" href=\"{}\">Details</a>'.format(url)\n",
    "# display_in_full(df.style.format({'Code': link_code, 'Details': link_details}))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
